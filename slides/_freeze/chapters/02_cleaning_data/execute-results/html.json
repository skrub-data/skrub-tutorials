{
  "hash": "7ae0dd271cae78d0360ea425a5c42009",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Preprocessing data with the skrub `Cleaner`\"\nformat:\n    html:\n        toc: true\n    revealjs:\n        slide-number: true\n        toc: false\n        code-fold: false\n        code-tools: true\n\n---\n\n## Introduction\nIn this chapter, we will show how we can quickly pre-process and sanitize \ndata using skrub's `Cleaner`. \n\n\n## Using the skrub `Cleaner`\nThe `Cleaner` is intended to be a first step in preparing tabular data for \nanalysis or modeling, and can handle a variety of common data cleaning tasks\nautomatically. It is designed to work out-of-the-box with minimal configuration,\nalthough it is also possible to customize its behavior if needed.\n\nGiven a dataframe, the `Cleaner` applies a sequence of transformers to each column:\n\nConsider this example dataframe:\n\n::: {#568faa74 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(\n    {\n        \"numerical_1\": [1, 2, 3, 4, 5],\n        \"numerical_2\": [10.5, 20.3, None, 40.1, 50.2],\n        \"string_column\": [\"apple\", \"?\", \"banana\", \"cherry\", \"?\"],\n        \"datetime_column\": [\n            \"03 Jan 2020\",\n            \"04 Jan 2020\",\n            \"05 Jan 2020\",\n            \"06 Jan 2020\",\n            \"07 Jan 2020\",\n        ],\n        \"all_none\": [None, None, None, None, None],\n    }\n)\ndf\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>numerical_1</th>\n      <th>numerical_2</th>\n      <th>string_column</th>\n      <th>datetime_column</th>\n      <th>all_none</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>10.5</td>\n      <td>apple</td>\n      <td>03 Jan 2020</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20.3</td>\n      <td>?</td>\n      <td>04 Jan 2020</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>banana</td>\n      <td>05 Jan 2020</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>40.1</td>\n      <td>cherry</td>\n      <td>06 Jan 2020</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>50.2</td>\n      <td>?</td>\n      <td>07 Jan 2020</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThis dataframe has mixed type columns, with some of the missing values denoted\nas `None` and some `\"?\"`. The datetime column has a non-standard format and has\nbeen parsed as a string column. Finally, one of the columns is completely empty. \n\n::: {#c4536320 .cell execution_count=2}\n``` {.python .cell-code}\ndf.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5 entries, 0 to 4\nData columns (total 5 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   numerical_1      5 non-null      int64  \n 1   numerical_2      4 non-null      float64\n 2   string_column    5 non-null      object \n 3   datetime_column  5 non-null      object \n 4   all_none         0 non-null      object \ndtypes: float64(1), int64(1), object(3)\nmemory usage: 332.0+ bytes\n```\n:::\n:::\n\n\n### Using plain pandas\nCleaning this dataset using plain pandas may require writing code like this:\n\n::: {#e5e5835c .cell execution_count=3}\n``` {.python .cell-code}\n# Parse the datetime strings with a specific format\ndf['datetime_column'] = pd.to_datetime(df['datetime_column'], format='%d %b %Y')\n\n# Drop columns with only a single unique value\ndf_clean = df.loc[:, df.nunique(dropna=True) > 1]\n\n# Replace \"?\" with np.nan in all string columns\ndf_clean = df_clean.replace(\"?\", np.nan)\n\n# Function to drop columns with only missing values or empty strings\ndef drop_empty_columns(df):\n    # Drop columns with only missing values\n    df_clean = df.dropna(axis=1, how='all')\n    # Drop columns with only empty strings\n    empty_string_cols = df_clean.columns[df_clean.eq('').all()]\n    df_clean = df_clean.drop(columns=empty_string_cols)\n    return df_clean\n\n# Apply the function to the DataFrame\ndf_clean = drop_empty_columns(df_clean)\ndf_clean\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>numerical_1</th>\n      <th>numerical_2</th>\n      <th>string_column</th>\n      <th>datetime_column</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>10.5</td>\n      <td>apple</td>\n      <td>2020-01-03</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20.3</td>\n      <td>NaN</td>\n      <td>2020-01-04</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>banana</td>\n      <td>2020-01-05</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>40.1</td>\n      <td>cherry</td>\n      <td>2020-01-06</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>50.2</td>\n      <td>NaN</td>\n      <td>2020-01-07</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### The alternative: `skrub.Cleaner`\n\nBy default, the `Cleaner` applies various transformations that can sanitize many\ncommon use cases:\n\n::: {#65d87a44 .cell execution_count=4}\n``` {.python .cell-code}\nfrom skrub import Cleaner\ndf_clean = Cleaner().fit_transform(df)\ndf_clean\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>numerical_1</th>\n      <th>numerical_2</th>\n      <th>string_column</th>\n      <th>datetime_column</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>10.5</td>\n      <td>apple</td>\n      <td>2020-01-03</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20.3</td>\n      <td>None</td>\n      <td>2020-01-04</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>banana</td>\n      <td>2020-01-05</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>40.1</td>\n      <td>cherry</td>\n      <td>2020-01-06</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>50.2</td>\n      <td>None</td>\n      <td>2020-01-07</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWe can see that the cleaned version of the dataframe is now marking missing values\ncorrectly, and that the datetime column has been parsed accordingly:\n\n::: {#4701a0c0 .cell execution_count=5}\n``` {.python .cell-code}\ndf_clean.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5 entries, 0 to 4\nData columns (total 4 columns):\n #   Column           Non-Null Count  Dtype         \n---  ------           --------------  -----         \n 0   numerical_1      5 non-null      int64         \n 1   numerical_2      4 non-null      float64       \n 2   string_column    3 non-null      object        \n 3   datetime_column  5 non-null      datetime64[ns]\ndtypes: datetime64[ns](1), float64(1), int64(1), object(1)\nmemory usage: 292.0+ bytes\n```\n:::\n:::\n\n\n::: {.content-hidden when-format=\"revealjs\"}\n\n### Cleaning steps performed by the `Cleaner` \nIn more detail, the `Cleaner` executes the following steps in order: \n\n1. It replaces common strings used to represent missing values (e.g., `NULL`, `?`)\nwith NA markers. \n2. It uses the `DropUninformative` transformer to decide whether a column is \n\"uninformative\", that is, it is not likely to bring information useful to train\na ML model. For example, empty columns are uninformative. \n3. It tries to parse datetime columns using common formats, or a user-provided\n`datetime_format`. \n4. It processes categorical columns to ensure consistent typing depending on the \ndataframe library in use. \n5. It converts columns to string, unless they have a data type that carries more \ninformation, such as numerical, datetime, and categorial columns. \n6. It automatically parses numbers written as strings (\"1.324\") to convert them \nto actual numerical columns.\n6. Finally, it can convert numerical columns to `np.float32` dtype if called \nwith the parameter `numeric_dtype=\"float32\"`. This ensures a consistent\nrepresentation of numbers and missing values, and helps reducing the memory footprint. \n\n\n:::\n\n## Under the hood: `DropUninformative`\nWhen the `Cleaner` is fitted on a dataframe, it checks whether the dataframe includes\nuninformative columns, that is columns that do not bring useful information for \ntraining a ML model, and should therefore be dropped.\n\nThis is done by the `DropUninformative` transformer, which is a standalone transformer\nthat the `Cleaner` leverages to sanitize data. \n`DropUninformative` marks a columns as \"uninformative\" if it satisfies one of these \nconditions:\n\n- The fraction of missing values is larger than the threshold provided by the user\nwith `drop_null_fraction`. \n    - By default, this threshold is 1.0, i.e., only columns\n    that contain only missing values are dropped. \n    - Setting the threshold to `None` will disable this check and therefore retain\n    empty columns. \n- It contains only one value, and no missing values. \n    - This is controlled by the `drop_if_constant` flag, which is `False` by \n    default. \n- All values in the column are distinct. \n    - This may be the case if the column contains\n    UIDs, but it can also happen when the column contains text. \n    - This check is off by default and can be turned on by setting \n    `drop_if_unique` to `True`. \n\n::: {#dd2bd0f5 .cell execution_count=6}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\n\ndf2 = pd.DataFrame({\n    \"id\": [101, 102, 103, 104, 105],\n    \"age\": [34, 28, 45, 52, 39],\n    \"salary\": [70000, None, 85000, None, None], \n    \"department\": [\"HR\", \"Finance\", \"IT\", \"HR\", \"Finance\"],\n    \"constant_col\": [\"active\"] * 5,  # single constant value\n})\ndf2\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>salary</th>\n      <th>department</th>\n      <th>constant_col</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>101</td>\n      <td>34</td>\n      <td>70000.0</td>\n      <td>HR</td>\n      <td>active</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>102</td>\n      <td>28</td>\n      <td>NaN</td>\n      <td>Finance</td>\n      <td>active</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>103</td>\n      <td>45</td>\n      <td>85000.0</td>\n      <td>IT</td>\n      <td>active</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>104</td>\n      <td>52</td>\n      <td>NaN</td>\n      <td>HR</td>\n      <td>active</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>105</td>\n      <td>39</td>\n      <td>NaN</td>\n      <td>Finance</td>\n      <td>active</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#dcdd2c05 .cell execution_count=7}\n``` {.python .cell-code}\nfrom skrub import ApplyToCols, DropUninformative\n\ndrop = ApplyToCols(DropUninformative(drop_if_constant=True, drop_null_fraction=0.5))\ndrop.fit_transform(df2)\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>department</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>101</td>\n      <td>34</td>\n      <td>HR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>102</td>\n      <td>28</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>103</td>\n      <td>45</td>\n      <td>IT</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>104</td>\n      <td>52</td>\n      <td>HR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>105</td>\n      <td>39</td>\n      <td>Finance</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Conclusion\nIn this chapter we have covered how the skrub `Cleaner` helps with sanitizing data\nby implementing a number of common transformations that need to be executed in \norder to ensure that the data used by the pipeline are consistent and can be used\nas indended by ML models. \n\n\n- The `Cleaner` object automates common data cleaning steps, making it easy to prepare tabular data for analysis or modeling with minimal configuration.\n- `Cleaner` leverages transformers like `DropUninformative` to automatically remove columns that are empty, constant, or contain mostly unique values (such as IDs), based on user-defined thresholds.\n- The `DropUninformative` transformer can also be used directly for fine-grained control over which columns to drop, according to missing value fraction, constant values, or uniqueness.\n- skrub objects are designed to work seamlessly with pandas DataFrames, streamlining the preprocessing workflow and reducing the need for manual data cleaning code.\n\n\n\n\nIn the next chapter we will see how skrub helps with applying this and other \ntransformations to specific columns in the data.\n\n\n# Exercise\n\n**Path to the exercise**: `../notebooks/01_ex_explore_clean.html`\n\n",
    "supporting": [
      "02_cleaning_data_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js\" integrity=\"sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js\" integrity=\"sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}