{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71c79bad",
   "metadata": {},
   "source": [
    "# Exercise: implementing a `TableVectorizer` from its components\n",
    "Replicate the behavior of a `TableVectorizer` using `ApplyToCols`, the skrub \n",
    "selectors, and the given transformers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5485349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import Cleaner, ApplyToCols, StringEncoder, DatetimeEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import skrub.selectors as s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef6beda",
   "metadata": {},
   "source": [
    "Notes on the implementation: \n",
    "\n",
    "- In the first step, the TableVectorizer cleans the data to parse datetimes and other\n",
    "dtypes.\n",
    "- Numeric features are left untouched, i.e., they use a Passthrough transformer. \n",
    "- String and categorical feature are split into high and low cardinality features. \n",
    "- For this exercise, set the the cardinality `threshold` to 4. \n",
    "- High cardinality features are transformed with a `StringEncoder`. In this exercise,\n",
    "set `n_components` to 2. \n",
    "- Low cardinality features are transformed with a `OneHotEncoder`, and the first \n",
    "category in binary features is dropped (hint: check the docs of the `OneHotEncoder`\n",
    "for the `drop` parameter). Set `sparse_output=True`.\n",
    "- Remember  `cardinality_below` is one of the skrub selectors. \n",
    "- Datetimes are transformed by a default `DatetimeEncoder`. \n",
    "- Everything should be wrapped in a scikit-learn `Pipeline`. \n",
    "\n",
    "\n",
    "Use the following dataframe to test the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58c114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "data = {\n",
    "    \"int\": [15, 56, 63, 12, 44],\n",
    "    \"float\": [5.2, 2.4, 6.2, 10.45, 9.0],\n",
    "    \"str1\": [\"public\", \"private\", \"private\", \"private\", \"public\"],\n",
    "    \"str2\": [\"officer\", \"manager\", \"lawyer\", \"chef\", \"teacher\"],\n",
    "    \"bool\": [True, False, True, False, True],\n",
    "    \"datetime-col\": [\n",
    "            \"2020-02-03T12:30:05\",\n",
    "            \"2021-03-15T00:37:15\",\n",
    "            \"2022-02-13T17:03:25\",\n",
    "            \"2023-05-22T08:45:55\",\n",
    "    ]\n",
    "    + [None],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256683b8",
   "metadata": {},
   "source": [
    "Use the following `PassThrough` transformer where needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc38a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub._apply_to_cols import SingleColumnTransformer\n",
    "class PassThrough(SingleColumnTransformer):\n",
    "    def fit_transform(self, column, y=None):\n",
    "        return column\n",
    "\n",
    "    def transform(self, column):\n",
    "        return column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c45493",
   "metadata": {},
   "source": [
    "You can test the correctness of your solution by comparing it with the equivalent\n",
    "`TableVectorizer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180a8fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import TableVectorizer\n",
    "\n",
    "tv = TableVectorizer(\n",
    "    high_cardinality=StringEncoder(n_components=2), cardinality_threshold=4\n",
    ")\n",
    "tv.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f6945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "#\n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47e349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "cleaner = ApplyToCols(Cleaner(numeric_dtype=\"float32\"))\n",
    "high_cardinality = ApplyToCols(\n",
    "    StringEncoder(n_components=2), cols=~s.cardinality_below(4) & (s.string())\n",
    ")\n",
    "low_cardinality = ApplyToCols(\n",
    "    OneHotEncoder(sparse_output=False, drop=\"if_binary\"),\n",
    "    cols=s.cardinality_below(4) & s.string(),\n",
    ")\n",
    "numeric = ApplyToCols(PassThrough(), cols=s.numeric())\n",
    "datetime = ApplyToCols(DatetimeEncoder(), cols=s.any_date())\n",
    "\n",
    "my_table_vectorizer = make_pipeline(\n",
    "    cleaner, numeric, high_cardinality, low_cardinality, datetime\n",
    ")\n",
    "\n",
    "my_table_vectorizer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3378d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
