{
  "hash": "19bbcdfe6958b1afff9f156d54a05b6b",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"All the pre-processing in one place: `TableVectorizer`\"\nformat:\n    revealjs:\n        slide-number: true\n        toc: true\n        code-fold: false\n        code-tools: true\n\n---\n\n## What is the TableVectorizer?\n\nMachine learning models typically require numeric input features. When working\nwith real-world datasets, we often have a mix of data types: numbers, text,\ndates, and categorical values. The `TableVectorizer` automates the entire process\nof converting a heterogeneous dataframe into a matrix of numeric features ready\nfor machine learning.\n\nInstead of manually specifying how to handle each column, the `TableVectorizer`\nautomatically detects the data type of each column and applies the appropriate\ntransformation to encode the column using numerical features. \n\n## How does the TableVectorizer work?\n\nThe `TableVectorizer` operates in two phases:\n\n### Phase 1: Data Cleaning and Type Detection\n\nFirst, it runs a `Cleaner` on the input data to:\n- Detect and parse datetime columns (possibly, with custom datetime formats)\n- Handle missing values represented as strings (e.g., \"N/A\")\n- Clean up categorical columns to have consistent typing\n- Remove uninformative columns (those with only nulls, constant values, or all\nunique values)\n- Finally, convert all numerical features to `float32` to reduce the computational\ncost. \n\nThis ensures that each column has the correct data type before encoding.\n\n### Phase 2: Column Dispatch and Encoding\n\nAfter cleaning, the `TableVectorizer` categorizes columns and dispatches them\nto the appropriate transformer based on their data type and cardinality.\n\nThe `TableVectorizer` uses the following default transformers for each column type:\n\n- **Numeric columns**: Left untouched (passthrough) - they're already in the\nright format\n- **Datetime columns**: Transformed by `DatetimeEncoder` to extract meaningful\ntemporal features\n- **Low-cardinality categorical/string columns**: Transformed with `OneHotEncoder`\nto create binary indicator variables\n- **High-cardinality categorical/string columns**: Transformed with `StringEncoder`\nto create dense numeric representations\n\n## Key Parameters\n\n### Cardinality Threshold\n\nBy default, columns with 40 or fewer unique values are considered \"low-cardinality\"\nand one-hot encoded, while those with more unique values are \"high-cardinality\"\nand encoded with `StringEncoder`. We can change this threshold:\n\n::: {#8df923eb .cell execution_count=1}\n``` {.python .cell-code}\nfrom skrub import TableVectorizer\n\ntv = TableVectorizer(cardinality_threshold=30)  # Adjust the threshold\n```\n:::\n\n\n### Data Cleaning Parameters\n\nThe `TableVectorizer` forwards several parameters to the internal `Cleaner`:\n\n- `drop_null_fraction`: Fraction of nulls above which a column is dropped (default: `1.0`)\n- `drop_if_constant`: Drop columns with only one unique value (default: `False`)\n- `drop_if_unique`: Drop string/categorical columns where all values are unique \n(default: `False`) \n- `datetime_format`: Format string for parsing dates\n\nNote that for `drop_if_constant` null values count as one additional distinct value.\n`drop_if_unique` should be used with care when working with free-flowing text,\nas in this case it is quite likely that all strings will be different, but the\ncolumn is not uninformative. \n\n::: {#45a809f7 .cell execution_count=2}\n``` {.python .cell-code}\ntv = TableVectorizer(\n    drop_null_fraction=0.9,  # Drop columns that are 90% null\n    drop_if_constant=True,\n    datetime_format=\"%Y-%m-%d\"\n)\n```\n:::\n\n\n### Specifying Custom Transformers\n\nThe `TableVectorizer` applies whatever transformer is provided to each of the \n`numeric`, `datetime`, `high_cardinality`, and `low_cardinality` paramters. To\ntweak the default parameters of the transformers a new transformer should be \nprovided: \n\n::: {#a7c88f01 .cell execution_count=3}\n``` {.python .cell-code}\nfrom skrub import TableVectorizer, DatetimeEncoder, StringEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Create custom transformers\ndatetime_enc = DatetimeEncoder(periodic_encoding=\"circular\")\nstring_enc = StringEncoder(n_components=10)\n\n# Pass them to TableVectorizer\ntv = TableVectorizer(\n    datetime=datetime_enc,\n    high_cardinality=string_enc,\n    low_cardinality=OneHotEncoder(sparse_output=False)\n)\n```\n:::\n\n\nThis allows to, for example, change the neumber of parameters in the `StringEncoder`, \nor provide a custom datetime format for the `DatetimeEncoder`. \n\n\n## Using `specific_transformers` for Column-Specific Control\n\nFor fine-grained control, we can specify transformers for specific columns using\nthe `specific_transformers` parameter. This is useful when we want to override\nthe default behavior for particular columns:\n\n::: {#6d8e1403 .cell execution_count=4}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import OrdinalEncoder\nimport pandas as pd\n\ndf = pd.DataFrame({\n    \"occupation\": [\"engineer\", \"teacher\", \"doctor\"],\n    \"salary\": [100000, 50000, 150000]\n})\n\n# Create a custom transformer for the 'occupation' column\nspecific_transformers = [(OrdinalEncoder(), [\"occupation\"])]\n\ntv = TableVectorizer(specific_transformers=specific_transformers)\nresult = tv.fit_transform(df)\n```\n:::\n\n\nImportant notes about `specific_transformers`:\n\n- Columns specified here bypass the default categorization logic\n- The transformer receives the column as-is, without any preprocessing\n- The transformer must be able to handle the column's current data type and values\n- For more complex transformations, consider using `ApplyToCols` and the selectors API\n(explained in the previous chapters), or the skrub\n[Data Ops](https://skrub-data.org/stable/auto_examples/data_ops/11_data_ops_intro.html).\n\n# Exercise: implementing a `TableVectorizer` from its components\nReplicate the behavior of a `TableVectorizer` using `ApplyToCols`, the skrub \nselectors, and the given transformers. \n\n::: {#6e507d2b .cell execution_count=5}\n``` {.python .cell-code}\nfrom skrub import Cleaner, ApplyToCols, StringEncoder, DatetimeEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import make_pipeline\nimport skrub.selectors as s\n```\n:::\n\n\nNotes on the implementation: \n\n- In the first step, the TableVectorizer cleans the data to parse datetimes and other\ndtypes.\n- Numeric features are left untouched, i.e., they use a Passthrough transformer. \n- String and categorical feature are split into high and low cardinality features. \n- For this exercise, set the the cardinality `threshold` to 4. \n- High cardinality features are transformed with a `StringEncoder`. In this exercise,\nset `n_components` to 2. \n- Low cardinality features are transformed with a `OneHotEncoder`, and the first \ncategory in binary features is dropped (hint: check the docs of the `OneHotEncoder`\nfor the `drop` parameter). Set `sparse_output=True`.\n- Remember  `cardinality_below` is one of the skrub selectors. \n- Datetimes are transformed by a default `DatetimeEncoder`. \n- Everything should be wrapped in a scikit-learn `Pipeline`. \n\n\nUse the following dataframe to test the result. \n\n::: {#dd3454b5 .cell execution_count=6}\n``` {.python .cell-code}\nimport pandas as pd\nimport datetime\n\ndata = {\n    \"int\": [15, 56, 63, 12, 44],\n    \"float\": [5.2, 2.4, 6.2, 10.45, 9.0],\n    \"str1\": [\"public\", \"private\", \"private\", \"private\", \"public\"],\n    \"str2\": [\"officer\", \"manager\", \"lawyer\", \"chef\", \"teacher\"],\n    \"bool\": [True, False, True, False, True],\n    \"datetime-col\": [\n            \"2020-02-03T12:30:05\",\n            \"2021-03-15T00:37:15\",\n            \"2022-02-13T17:03:25\",\n            \"2023-05-22T08:45:55\",\n    ]\n    + [None],\n}\ndf = pd.DataFrame(data)\ndf\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>int</th>\n      <th>float</th>\n      <th>str1</th>\n      <th>str2</th>\n      <th>bool</th>\n      <th>datetime-col</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15</td>\n      <td>5.20</td>\n      <td>public</td>\n      <td>officer</td>\n      <td>True</td>\n      <td>2020-02-03T12:30:05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>56</td>\n      <td>2.40</td>\n      <td>private</td>\n      <td>manager</td>\n      <td>False</td>\n      <td>2021-03-15T00:37:15</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>63</td>\n      <td>6.20</td>\n      <td>private</td>\n      <td>lawyer</td>\n      <td>True</td>\n      <td>2022-02-13T17:03:25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12</td>\n      <td>10.45</td>\n      <td>private</td>\n      <td>chef</td>\n      <td>False</td>\n      <td>2023-05-22T08:45:55</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>44</td>\n      <td>9.00</td>\n      <td>public</td>\n      <td>teacher</td>\n      <td>True</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nUse the following `PassThrough` transformer where needed. \n\n::: {#5325f87a .cell execution_count=7}\n``` {.python .cell-code}\nfrom skrub._apply_to_cols import SingleColumnTransformer\nclass PassThrough(SingleColumnTransformer):\n    def fit_transform(self, column, y=None):\n        return column\n\n    def transform(self, column):\n        return column\n```\n:::\n\n\nYou can test the correctness of your solution by comparing it with the equivalent\n`TableVectorizer`:\n\n::: {#1bff52ff .cell execution_count=8}\n``` {.python .cell-code}\nfrom skrub import TableVectorizer\n\ntv = TableVectorizer(\n    high_cardinality=StringEncoder(n_components=2), cardinality_threshold=4\n)\ntv.fit_transform(df)\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>int</th>\n      <th>float</th>\n      <th>str1_public</th>\n      <th>str2_0</th>\n      <th>str2_1</th>\n      <th>bool</th>\n      <th>datetime-col_year</th>\n      <th>datetime-col_month</th>\n      <th>datetime-col_day</th>\n      <th>datetime-col_hour</th>\n      <th>datetime-col_total_seconds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15.0</td>\n      <td>5.20</td>\n      <td>1.0</td>\n      <td>0.820972</td>\n      <td>-0.926897</td>\n      <td>1.0</td>\n      <td>2020.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>12.0</td>\n      <td>1.580733e+09</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>56.0</td>\n      <td>2.40</td>\n      <td>0.0</td>\n      <td>0.820966</td>\n      <td>-0.926892</td>\n      <td>0.0</td>\n      <td>2021.0</td>\n      <td>3.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>1.615769e+09</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>63.0</td>\n      <td>6.20</td>\n      <td>0.0</td>\n      <td>0.862893</td>\n      <td>-0.936521</td>\n      <td>1.0</td>\n      <td>2022.0</td>\n      <td>2.0</td>\n      <td>13.0</td>\n      <td>17.0</td>\n      <td>1.644772e+09</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12.0</td>\n      <td>10.45</td>\n      <td>0.0</td>\n      <td>1.029679</td>\n      <td>1.352998</td>\n      <td>0.0</td>\n      <td>2023.0</td>\n      <td>5.0</td>\n      <td>22.0</td>\n      <td>8.0</td>\n      <td>1.684745e+09</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>44.0</td>\n      <td>9.00</td>\n      <td>1.0</td>\n      <td>1.419119</td>\n      <td>0.660175</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#2d362fc0 .cell execution_count=9}\n``` {.python .cell-code}\n# Write your code here\n#\n# \n# \n# \n# \n# \n# \n# \n# \n# \n# \n# \n```\n:::\n\n\n::: {#9046e673 .cell execution_count=10}\n``` {.python .cell-code}\n# Solution\ncleaner = ApplyToCols(Cleaner())\nhigh_cardinality = ApplyToCols(\n    StringEncoder(n_components=2), cols=~s.cardinality_below(4) & (s.string())\n)\nlow_cardinality = ApplyToCols(\n    OneHotEncoder(sparse_output=False, drop=\"if_binary\"),\n    cols=s.cardinality_below(4) & s.string(),\n)\nnumeric = ApplyToCols(PassThrough(), cols=s.numeric())\ndatetime = ApplyToCols(DatetimeEncoder(), cols=s.any_date())\n\nmy_table_vectorizer = make_pipeline(\n    cleaner, numeric, high_cardinality, low_cardinality, datetime\n)\n\nmy_table_vectorizer.fit_transform(df)\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>int</th>\n      <th>float</th>\n      <th>str1_public</th>\n      <th>str2_0</th>\n      <th>str2_1</th>\n      <th>bool</th>\n      <th>datetime-col_year</th>\n      <th>datetime-col_month</th>\n      <th>datetime-col_day</th>\n      <th>datetime-col_hour</th>\n      <th>datetime-col_total_seconds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15</td>\n      <td>5.20</td>\n      <td>1.0</td>\n      <td>0.820969</td>\n      <td>-0.926899</td>\n      <td>True</td>\n      <td>2020.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>12.0</td>\n      <td>1.580733e+09</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>56</td>\n      <td>2.40</td>\n      <td>0.0</td>\n      <td>0.820957</td>\n      <td>-0.926896</td>\n      <td>False</td>\n      <td>2021.0</td>\n      <td>3.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>1.615769e+09</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>63</td>\n      <td>6.20</td>\n      <td>0.0</td>\n      <td>0.862892</td>\n      <td>-0.936525</td>\n      <td>True</td>\n      <td>2022.0</td>\n      <td>2.0</td>\n      <td>13.0</td>\n      <td>17.0</td>\n      <td>1.644772e+09</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12</td>\n      <td>10.45</td>\n      <td>0.0</td>\n      <td>1.029688</td>\n      <td>1.352998</td>\n      <td>False</td>\n      <td>2023.0</td>\n      <td>5.0</td>\n      <td>22.0</td>\n      <td>8.0</td>\n      <td>1.684745e+09</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>44</td>\n      <td>9.00</td>\n      <td>1.0</td>\n      <td>1.419121</td>\n      <td>0.660163</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n",
    "supporting": [
      "08_feat_eng_table_vect_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js\" integrity=\"sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js\" integrity=\"sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}