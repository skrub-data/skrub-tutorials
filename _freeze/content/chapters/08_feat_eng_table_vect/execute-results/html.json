{
  "hash": "57c7d13783ad548182e311c0be460a55",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"All the pre-processing in one place: `TableVectorizer`\"\nformat:\n    revealjs:\n        slide-number: true\n        toc: true\n        code-fold: false\n        code-tools: true\n\n---\n\n## Introduction\n\nMachine learning models typically require numeric input features. When working\nwith real-world datasets, we often have a mix of data types: numbers, text,\ndates, and categorical values. The `TableVectorizer` automates the entire process\nof converting a heterogeneous dataframe into a matrix of numeric features ready\nfor machine learning.\n\nInstead of manually specifying how to handle each column, the `TableVectorizer`\nautomatically detects the data type of each column and applies the appropriate\ntransformation to encode the column using numerical features. \n\n## How does the TableVectorizer work?\n\nThe `TableVectorizer` operates in two phases:\n\n### Phase 1: Data cleaning and type detection\n\nFirst, it runs a `Cleaner` on the input data to:\n\n- Detect and parse datetime columns (possibly, with custom datetime formats)\n- Detect and parse numerical columns written as strings\n- Handle missing values represented as strings (e.g., \"N/A\")\n- Clean up categorical columns to have consistent typing\n- Remove uninformative columns (those with only nulls, constant values, or all\nunique values)\n- Finally, convert all numerical features to `float32` to reduce the computational\ncost. \n\nThis ensures that each column has the correct data type before encoding.\n\n### Phase 2: Column dispatch and encoding\n\nAfter cleaning, the `TableVectorizer` categorizes columns and dispatches them\nto the appropriate transformer based on their data type and cardinality. Categorical\ncolumns with a cardinality (i.e., number of unique values) larger than 40 (by\ndefault)) are \nconsidered \"high cardinality\", while all other categorical columns are \"low \ncardinality\".\n\nThe `TableVectorizer` uses the following default transformers for each column type:\n\n- **Numeric columns**: Left untouched (passthrough) - they're already in the\nright format\n- **Datetime columns**: Transformed by `DatetimeEncoder` to extract meaningful\ntemporal features\n- **Low-cardinality categorical/string columns**: Transformed with `OneHotEncoder`\nto create binary indicator variables\n- **High-cardinality categorical/string columns**: Transformed with `StringEncoder`\nto create dense numeric representations\n\n## Key Parameters\n\n### Cardinality threshold\n\nThe cardinality threshold that splits columns in \"high\" and \"low\" cardinality\ncan be changed by setting the relative parameter:\n\n::: {#00edead8 .cell execution_count=1}\n``` {.python .cell-code}\nfrom skrub import TableVectorizer\n\ntv = TableVectorizer(cardinality_threshold=10)  # Adjust the threshold\n```\n:::\n\n\n### Data cleaning parameters\n\nThe `TableVectorizer` forwards several parameters to the internal `Cleaner`, \nwhich behave in the same way:\n\n- `drop_null_fraction`: Fraction of nulls above which a column is dropped (default: `1.0`)\n- `drop_if_constant`: Drop columns with only one unique value (default: `False`)\n- `drop_if_unique`: Drop string/categorical columns where all values are unique \n(default: `False`) \n- `datetime_format`: Format string for parsing dates\n\n::: {#9d5c9a81 .cell execution_count=2}\n``` {.python .cell-code}\ntv = TableVectorizer(\n    drop_null_fraction=0.9,  # Drop columns that are 90% null\n    drop_if_constant=True,\n    datetime_format=\"%Y-%m-%d\"\n)\n```\n:::\n\n\n### Customizing the transformers used by `TableVectorizer`\n\nThe `TableVectorizer` applies whatever transformer is provided to each of the \n`numeric`, `datetime`, `high_cardinality`, and `low_cardinality` paramters. To\ntweak the default parameters of the transformers a new transformer should be \nprovided: \n\n::: {#02089cd2 .cell execution_count=3}\n``` {.python .cell-code}\nfrom skrub import TableVectorizer, DatetimeEncoder, StringEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Create custom transformers\ndatetime_enc = DatetimeEncoder(periodic_encoding=\"circular\")\nstring_enc = StringEncoder(n_components=10)\n\n# Pass them to TableVectorizer\ntv = TableVectorizer(\n    datetime=datetime_enc,\n    high_cardinality=string_enc,\n)\n```\n:::\n\n\nThis allows to, for example, change the number of parameters in the `StringEncoder`, \nprovide a custom datetime format for the `DatetimeEncoder`, or use a completely \ndifferent encoder such as the `TextEncoder`. \n\n### Applying the `TableVectorizer` only to a subset of columns\nBy default, the `TableVectorizer` is applied to all the columns in the given \ndataframe. In some cases, it may be important to keep specific columns \"as is\", so\nthat they are not modified by the transformer. \n\nThis can be done by wrapping the vectorizer into an `ApplyToCols` object. \n\nFor example, in this case we might want to avoid modifying the two `*_id` columns. \n\n::: {#edad01fa .cell execution_count=4}\n``` {.python .cell-code}\nimport pandas as pd\nfrom skrub import ApplyToCols\nimport skrub.selectors as s\n\ndf = pd.DataFrame(\n    {\n        \"metric_1\": [10.5, 20.3, 30.1, 40.2],\n        \"metric_2\": [5.1, 15.6, None, 35.8],\n        \"metric_3\": [1.1, 3.3, 2.6, .8],\n        \"num_id\": [101, 102, 103, 104],\n        \"str_id\": [\"A101\", \"A102\", \"A103\", \"A104\"],\n        \"description\": [\"apple\", None, \"cherry\", \"date\"],\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n    }\n)\ndf\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric_1</th>\n      <th>metric_2</th>\n      <th>metric_3</th>\n      <th>num_id</th>\n      <th>str_id</th>\n      <th>description</th>\n      <th>name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10.5</td>\n      <td>5.1</td>\n      <td>1.1</td>\n      <td>101</td>\n      <td>A101</td>\n      <td>apple</td>\n      <td>Alice</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.3</td>\n      <td>15.6</td>\n      <td>3.3</td>\n      <td>102</td>\n      <td>A102</td>\n      <td>None</td>\n      <td>Bob</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30.1</td>\n      <td>NaN</td>\n      <td>2.6</td>\n      <td>103</td>\n      <td>A103</td>\n      <td>cherry</td>\n      <td>Charlie</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>40.2</td>\n      <td>35.8</td>\n      <td>0.8</td>\n      <td>104</td>\n      <td>A104</td>\n      <td>date</td>\n      <td>David</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWe can use `ApplyToCols` and the skrub selectors as follows: \n\n::: {#5be9d9e6 .cell execution_count=5}\n``` {.python .cell-code}\ntv = ApplyToCols(TableVectorizer(), cols=s.all()-s.glob(\"*_id\"))\ndf_enc = tv.fit_transform(df)\n\nprint(\"Original\")\nprint(df[[\"num_id\", \"str_id\"]])\nprint(\"\\nEncoded\")\nprint(df_enc[[\"num_id\", \"str_id\"]])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOriginal\n   num_id str_id\n0     101   A101\n1     102   A102\n2     103   A103\n3     104   A104\n\nEncoded\n   num_id str_id\n0     101   A101\n1     102   A102\n2     103   A103\n3     104   A104\n```\n:::\n:::\n\n\nThe id strings are the same, while all other columns have been encoded as expected.\n\n### Using `specific_transformers` for more low-level control\n\nFor fine-grained control, we can specify transformers for specific columns using\nthe `specific_transformers` parameter. This is useful when we want to override\nthe default behavior for particular columns:\n\n::: {#9a12d204 .cell execution_count=6}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import OrdinalEncoder\nimport pandas as pd\n\ndf = pd.DataFrame({\n    \"occupation\": [\"engineer\", \"teacher\", \"doctor\"],\n    \"salary\": [100000, 50000, 150000]\n})\n\n# Create a custom transformer for the 'occupation' column\nspecific_transformers = [(OrdinalEncoder(), [\"occupation\"])]\n\ntv = TableVectorizer(specific_transformers=specific_transformers)\nresult = tv.fit_transform(df)\n```\n:::\n\n\nImportant notes about `specific_transformers`:\n\n- Columns specified here bypass the default categorization logic\n- The transformer receives the column as-is, without any preprocessing\n- The transformer must be able to handle the column's current data type and values\n- For more complex transformations, consider using `ApplyToCols` and the selectors API\n(explained in the previous chapters), or the skrub\n[Data Ops](https://skrub-data.org/stable/auto_examples/data_ops/11_data_ops_intro.html).\n\n## Conclusions\nThe `TableVectorizer` is a self-contained feature engineering engine that \n\n1. Cleans your data to have consistent representation of data types and null values,\nand\n2. Encodes all columns depending on their data type and characteristics using good\ndefaults. \n\nThe idea behind the `TableVectorizer` is that you should be able to provide any \ndataframe, and get a good feature matrix based on that dataframe as a result. \n\nThe `TableVectorizer` makes use of most of the objects that have been explained\nso far, and is an important part of the `tabular_pipeline` explained in the \nnext chapter. \n\n\n# Exercise: implementing a `TableVectorizer` from its components\n\n**Path to the exercise**: `content/exercises/08_feat_eng_table_vect.ipynb`\n\nReplicate the behavior of a `TableVectorizer` using `ApplyToCols`, the skrub \nselectors, and the given transformers. \n\n::: {#d60ded2d .cell execution_count=7}\n``` {.python .cell-code}\nfrom skrub import Cleaner, ApplyToCols, StringEncoder, DatetimeEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import make_pipeline\nimport skrub.selectors as s\n```\n:::\n\n\nNotes on the implementation: \n\n- In the first step, the TableVectorizer cleans the data to parse datetimes and other\ndtypes with a `Cleaner` that uses default parameters, except for `numeric_dtype=\"float32\"`.\n- Numeric features are left untouched, i.e., they use a Passthrough transformer. \n- String and categorical feature are split into high and low cardinality features. \n- For this exercise, set the the cardinality `threshold` to 4. \n- High cardinality features are transformed with a `StringEncoder`. In this exercise,\nset `n_components` to 2. \n- Low cardinality features are transformed with a `OneHotEncoder`, and the first \ncategory in binary features is dropped (hint: check the docs of the `OneHotEncoder`\nfor the `drop` parameter). Set `sparse_output=True`.\n- Remember  `cardinality_below` is one of the skrub selectors. \n- Datetimes are transformed by a default `DatetimeEncoder`. \n- Everything should be wrapped in a scikit-learn `Pipeline` (or with `make_pipeline`).\n\n\n\nUse the following dataframe to test the result. \n\n::: {#e3f4b57b .cell execution_count=8}\n``` {.python .cell-code}\nimport pandas as pd\nimport datetime\n\ndata = {\n    \"int\": [15, 56, 63, 12, 44],\n    \"float\": [5.2, 2.4, 6.2, 10.45, 9.0],\n    \"str1\": [\"public\", \"private\", \"private\", \"private\", \"public\"],\n    \"str2\": [\"officer\", \"manager\", \"lawyer\", \"chef\", \"teacher\"],\n    \"bool\": [True, False, True, False, True],\n    \"datetime-col\": [\n        \"2020-02-03T12:30:05\",\n        \"2021-03-15T00:37:15\",\n        \"2022-02-13T17:03:25\",\n        \"2023-05-22T08:45:55\",\n    ]\n    + [None],\n}\ndf = pd.DataFrame(data)\ndf\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>int</th>\n      <th>float</th>\n      <th>str1</th>\n      <th>str2</th>\n      <th>bool</th>\n      <th>datetime-col</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15</td>\n      <td>5.20</td>\n      <td>public</td>\n      <td>officer</td>\n      <td>True</td>\n      <td>2020-02-03T12:30:05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>56</td>\n      <td>2.40</td>\n      <td>private</td>\n      <td>manager</td>\n      <td>False</td>\n      <td>2021-03-15T00:37:15</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>63</td>\n      <td>6.20</td>\n      <td>private</td>\n      <td>lawyer</td>\n      <td>True</td>\n      <td>2022-02-13T17:03:25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12</td>\n      <td>10.45</td>\n      <td>private</td>\n      <td>chef</td>\n      <td>False</td>\n      <td>2023-05-22T08:45:55</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>44</td>\n      <td>9.00</td>\n      <td>public</td>\n      <td>teacher</td>\n      <td>True</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nUse the following `PassThrough` transformer where needed. \n\n::: {#9ce7a10f .cell execution_count=9}\n``` {.python .cell-code}\nfrom skrub._apply_to_cols import SingleColumnTransformer\n\n\nclass PassThrough(SingleColumnTransformer):\n    def fit_transform(self, column, y=None):\n        return column\n\n    def transform(self, column):\n        return column\n```\n:::\n\n\nYou can test the correctness of your solution by comparing it with the equivalent\n`TableVectorizer`:\n\n::: {#9b6b5dec .cell execution_count=10}\n``` {.python .cell-code}\nfrom skrub import TableVectorizer\n\ntv = TableVectorizer(\n    high_cardinality=StringEncoder(n_components=2), cardinality_threshold=4\n)\ntv.fit_transform(df)\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>int</th>\n      <th>float</th>\n      <th>str1_public</th>\n      <th>str2_0</th>\n      <th>str2_1</th>\n      <th>bool</th>\n      <th>datetime-col_year</th>\n      <th>datetime-col_month</th>\n      <th>datetime-col_day</th>\n      <th>datetime-col_hour</th>\n      <th>datetime-col_total_seconds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15.0</td>\n      <td>5.20</td>\n      <td>1.0</td>\n      <td>0.820974</td>\n      <td>-0.926883</td>\n      <td>1.0</td>\n      <td>2020.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>12.0</td>\n      <td>1.580733e+09</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>56.0</td>\n      <td>2.40</td>\n      <td>0.0</td>\n      <td>0.820970</td>\n      <td>-0.926897</td>\n      <td>0.0</td>\n      <td>2021.0</td>\n      <td>3.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>1.615769e+09</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>63.0</td>\n      <td>6.20</td>\n      <td>0.0</td>\n      <td>0.862896</td>\n      <td>-0.936519</td>\n      <td>1.0</td>\n      <td>2022.0</td>\n      <td>2.0</td>\n      <td>13.0</td>\n      <td>17.0</td>\n      <td>1.644772e+09</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12.0</td>\n      <td>10.45</td>\n      <td>0.0</td>\n      <td>1.029678</td>\n      <td>1.353008</td>\n      <td>0.0</td>\n      <td>2023.0</td>\n      <td>5.0</td>\n      <td>22.0</td>\n      <td>8.0</td>\n      <td>1.684745e+09</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>44.0</td>\n      <td>9.00</td>\n      <td>1.0</td>\n      <td>1.419116</td>\n      <td>0.660171</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#2d938969 .cell execution_count=11}\n``` {.python .cell-code}\n# Write your code here\n#\n# \n# \n# \n# \n# \n# \n# \n# \n# \n# \n# \n```\n:::\n\n\n::: {#95150fb0 .cell execution_count=12}\n``` {.python .cell-code}\n# Solution\ncleaner = ApplyToCols(Cleaner())\nhigh_cardinality = ApplyToCols(\n    StringEncoder(n_components=2), cols=~s.cardinality_below(4) & (s.string())\n)\nlow_cardinality = ApplyToCols(\n    OneHotEncoder(sparse_output=False, drop=\"if_binary\"),\n    cols=s.cardinality_below(4) & s.string(),\n)\nnumeric = ApplyToCols(PassThrough(), cols=s.numeric())\ndatetime = ApplyToCols(DatetimeEncoder(), cols=s.any_date())\n\nmy_table_vectorizer = make_pipeline(\n    cleaner, numeric, high_cardinality, low_cardinality, datetime\n)\n\nmy_table_vectorizer.fit_transform(df)\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>int</th>\n      <th>float</th>\n      <th>str1_public</th>\n      <th>str2_0</th>\n      <th>str2_1</th>\n      <th>bool</th>\n      <th>datetime-col_year</th>\n      <th>datetime-col_month</th>\n      <th>datetime-col_day</th>\n      <th>datetime-col_hour</th>\n      <th>datetime-col_total_seconds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15</td>\n      <td>5.20</td>\n      <td>1.0</td>\n      <td>0.820968</td>\n      <td>-0.926893</td>\n      <td>True</td>\n      <td>2020.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>12.0</td>\n      <td>1.580733e+09</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>56</td>\n      <td>2.40</td>\n      <td>0.0</td>\n      <td>0.820969</td>\n      <td>-0.926902</td>\n      <td>False</td>\n      <td>2021.0</td>\n      <td>3.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>1.615769e+09</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>63</td>\n      <td>6.20</td>\n      <td>0.0</td>\n      <td>0.862895</td>\n      <td>-0.936510</td>\n      <td>True</td>\n      <td>2022.0</td>\n      <td>2.0</td>\n      <td>13.0</td>\n      <td>17.0</td>\n      <td>1.644772e+09</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12</td>\n      <td>10.45</td>\n      <td>0.0</td>\n      <td>1.029677</td>\n      <td>1.353003</td>\n      <td>False</td>\n      <td>2023.0</td>\n      <td>5.0</td>\n      <td>22.0</td>\n      <td>8.0</td>\n      <td>1.684745e+09</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>44</td>\n      <td>9.00</td>\n      <td>1.0</td>\n      <td>1.419119</td>\n      <td>0.660171</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n",
    "supporting": [
      "08_feat_eng_table_vect_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js\" integrity=\"sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js\" integrity=\"sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}