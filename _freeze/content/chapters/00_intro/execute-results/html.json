{
  "hash": "147320744386cf9f22554b438113b2e3",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"A world without skrub\"\nformat:\n    revealjs:\n        slide-number: true\n        toc: true\n        code-fold: false\n        code-tools: true\n\n---\n\nLet's begin the lesson by imagining a world without skrub, where we can use \nonly Pandas and scikit-learn to clean data and prepare a machine learning model. \n\n::: {#f81fb684 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\n\nX = pd.read_csv(\"../data/employee_salaries/data.csv\")\ny = pd.read_csv(\"../data/employee_salaries/target.csv\")\nX.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>department</th>\n      <th>department_name</th>\n      <th>division</th>\n      <th>assignment_category</th>\n      <th>employee_position_title</th>\n      <th>date_first_hired</th>\n      <th>year_first_hired</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>F</td>\n      <td>POL</td>\n      <td>Department of Police</td>\n      <td>MSB Information Mgmt and Tech Division Records...</td>\n      <td>Fulltime-Regular</td>\n      <td>Office Services Coordinator</td>\n      <td>09/22/1986</td>\n      <td>1986</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M</td>\n      <td>POL</td>\n      <td>Department of Police</td>\n      <td>ISB Major Crimes Division Fugitive Section</td>\n      <td>Fulltime-Regular</td>\n      <td>Master Police Officer</td>\n      <td>09/12/1988</td>\n      <td>1988</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>F</td>\n      <td>HHS</td>\n      <td>Department of Health and Human Services</td>\n      <td>Adult Protective and Case Management Services</td>\n      <td>Fulltime-Regular</td>\n      <td>Social Worker IV</td>\n      <td>11/19/1989</td>\n      <td>1989</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M</td>\n      <td>COR</td>\n      <td>Correction and Rehabilitation</td>\n      <td>PRRS Facility and Security</td>\n      <td>Fulltime-Regular</td>\n      <td>Resident Supervisor II</td>\n      <td>05/05/2014</td>\n      <td>2014</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M</td>\n      <td>HCA</td>\n      <td>Department of Housing and Community Affairs</td>\n      <td>Affordable Housing Programs</td>\n      <td>Fulltime-Regular</td>\n      <td>Planning Specialist III</td>\n      <td>03/05/2007</td>\n      <td>2007</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nLet's take a look at the target::\n\n::: {#45758e02 .cell execution_count=2}\n``` {.python .cell-code}\ny.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>current_annual_salary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>69222.18</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>97392.47</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>104717.28</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>52734.57</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>93396.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThis is a numerical column, and our task is predicting the value of `current_annual_salary`.\n\n## Strategizing\nWe can begin by exploring the dataframe with `.describe`, and then think of a \nplan for pre-processing our data. \n\n::: {#cfe02c79 .cell execution_count=3}\n``` {.python .cell-code}\nX.describe(include=\"all\")\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gender</th>\n      <th>department</th>\n      <th>department_name</th>\n      <th>division</th>\n      <th>assignment_category</th>\n      <th>employee_position_title</th>\n      <th>date_first_hired</th>\n      <th>year_first_hired</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>9211</td>\n      <td>9228</td>\n      <td>9228</td>\n      <td>9228</td>\n      <td>9228</td>\n      <td>9228</td>\n      <td>9228</td>\n      <td>9228.000000</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>2</td>\n      <td>37</td>\n      <td>37</td>\n      <td>694</td>\n      <td>2</td>\n      <td>443</td>\n      <td>2264</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>M</td>\n      <td>POL</td>\n      <td>Department of Police</td>\n      <td>School Health Services</td>\n      <td>Fulltime-Regular</td>\n      <td>Bus Operator</td>\n      <td>12/12/2016</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>5481</td>\n      <td>1844</td>\n      <td>1844</td>\n      <td>300</td>\n      <td>8394</td>\n      <td>638</td>\n      <td>87</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2003.597529</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.327078</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1965.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1998.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2005.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2012.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2016.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nIn this example we want to train a regression model to predict the salary, and we\nwill be using a linear model (`Ridge`) to do so. \n\nTherefore, we need to: \n\n- Impute some missing values in the `gender` column.\n- Encode convert categorical features into numerical features. \n- Convert the column `date_first_hired` into numerical features.\n- Scale numerical features. \n\nFinally, we want to evaluate the performance of the method across multiple \ncross-validation splits.\n\n## Building a traditional pipeline\nLet's build a traditional predictive pipeline following the steps we just discussed. \n\n### Step 1: Convert date features to numerical\n\nExtract numerical features from the `date_first_hired` column.\n\n::: {#fd033d13 .cell execution_count=4}\n``` {.python .cell-code}\n# Create a copy to work with\nX_processed = X.copy()\n\n# Parse the date column\nX_processed['date_first_hired'] = pd.to_datetime(X_processed['date_first_hired'])\n\n# Extract numerical features from date\nX_processed['hired_month'] = X_processed['date_first_hired'].dt.month\nX_processed['hired_year'] = X_processed['date_first_hired'].dt.year\n\n# Drop original date column\nX_processed = X_processed.drop('date_first_hired', axis=1)\n\nprint(\"Features after date transformation:\")\nprint(\"\\nShape:\", X_processed.shape)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFeatures after date transformation:\n\nShape: (9228, 9)\n```\n:::\n:::\n\n\n### Step 2: Encode categorical features\n\nEncode only the non-numerical categorical features using one-hot encoding.\n\n::: {#59830daf .cell execution_count=5}\n``` {.python .cell-code}\n# Identify only the non-numerical (truly categorical) columns\ncategorical_cols = X_processed.select_dtypes(include=['object']).columns.tolist()\nprint(\"Categorical columns to encode:\", categorical_cols)\n\n# Apply one-hot encoding only to categorical columns\nX_encoded = pd.get_dummies(X_processed, columns=categorical_cols)\nprint(\"\\nShape after encoding:\", X_encoded.shape)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCategorical columns to encode: ['gender', 'department', 'department_name', 'division', 'assignment_category', 'employee_position_title']\n\nShape after encoding: (9228, 1218)\n```\n:::\n:::\n\n\n### Step 3: Impute missing values\n\nWe'll impute missing values in the `gender` column using the most frequent strategy.\n\n::: {#88514cf4 .cell execution_count=6}\n``` {.python .cell-code}\nfrom sklearn.impute import SimpleImputer\n\n# Impute missing values with most frequent value\nimputer = SimpleImputer(strategy='most_frequent')\nX_encoded_imputed = pd.DataFrame(\n    imputer.fit_transform(X_encoded),\n    columns=X_encoded.columns\n)\n```\n:::\n\n\n### Step 4: Scale numerical features\n\nScale numerical features for the Ridge regression model.\n\n::: {#6a959e21 .cell execution_count=7}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import StandardScaler\n\n# Initialize the scaler\nscaler = StandardScaler()\n\n# Fit and transform the data\nX_scaled = scaler.fit_transform(X_encoded_imputed)\nX_scaled = pd.DataFrame(X_scaled, columns=X_encoded_imputed.columns)\n```\n:::\n\n\n### Step 5: Train Ridge model with cross-validation\n\nTrain a `Ridge` regression model and evaluate with cross-validation.\n\n::: {#e4839768 .cell execution_count=8}\n``` {.python .cell-code}\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import cross_val_score, cross_validate\nimport numpy as np\n\n# Initialize Ridge model\nridge = Ridge(alpha=1.0)\n\n# Perform cross-validation (5-fold)\ncv_results = cross_validate(\n    ridge,\n    X_scaled,\n    y,\n    cv=5,\n    scoring=[\"r2\", \"neg_mean_squared_error\"],\n)\n\n# Convert MSE to RMSE\ntest_rmse = np.sqrt(-cv_results[\"test_neg_mean_squared_error\"])\n\n# Display results\nprint(\"Cross-Validation Results:\")\nprint(\n    f\"Mean test R²: {cv_results['test_r2'].mean():.4f} (+/- {cv_results['test_r2'].std():.4f})\"\n)\nprint(f\"Mean test RMSE: {test_rmse.mean():.4f} (+/- {test_rmse.std():.4f})\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCross-Validation Results:\nMean test R²: 0.8722 (+/- 0.0274)\nMean test RMSE: 10367.1206 (+/- 1403.4322)\n```\n:::\n:::\n\n\n### \"Just ask an agent to write the code\"\nIt's what I did. Here are some of the issues I noticed: \n\n- Operations in the wrong order.\n- Trying to impute categorical features without encoding them as numerical values.\n- The datetime feature was encoded as a categorical (i.e, with dummmies).\n- Cells could not be executed in order without proper debugging and re-prompting.\n- `pd.get_dummies` was executed on the full dataframe, rather than only on the \ntraining split, leading to data leakage. \n\nThis means that I had to spend time re-prompting the model to get it to run, and \nthat's (intentionally) without removing the leakage. \n\n## Waking up from a nightmare\nThankfully, we live in a world where we can `import skrub`. Let's see what we can\nget if we use `skrub.tabular_pipeline`. \n\n::: {#269368ee .cell execution_count=9}\n``` {.python .cell-code}\nfrom skrub import tabular_pipeline\n\n# Perform cross-validation (5-fold)\ncv_results = cross_validate(tabular_pipeline(\"regression\"), X, y, cv=5, \n                            scoring=['r2', 'neg_mean_squared_error'],\n                            return_train_score=True)\n\n# Convert MSE to RMSE\ntrain_rmse = np.sqrt(-cv_results['train_neg_mean_squared_error'])\ntest_rmse = np.sqrt(-cv_results['test_neg_mean_squared_error'])\n\n# Display results\nprint(\"Cross-Validation Results:\")\nprint(f\"Mean test R²: {cv_results['test_r2'].mean():.4f} (+/- {cv_results['test_r2'].std():.4f})\")\nprint(f\"Mean test RMSE: {test_rmse.mean():.4f} (+/- {test_rmse.std():.4f})\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/rcap/work/skrub-tutorials/.pixi/envs/doc/lib/python3.14/site-packages/sklearn/utils/validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/Users/rcap/work/skrub-tutorials/.pixi/envs/doc/lib/python3.14/site-packages/sklearn/utils/validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/Users/rcap/work/skrub-tutorials/.pixi/envs/doc/lib/python3.14/site-packages/sklearn/utils/validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/Users/rcap/work/skrub-tutorials/.pixi/envs/doc/lib/python3.14/site-packages/sklearn/utils/validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n/Users/rcap/work/skrub-tutorials/.pixi/envs/doc/lib/python3.14/site-packages/sklearn/utils/validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nCross-Validation Results:\nMean test R²: 0.9105 (+/- 0.0160)\nMean test RMSE: 8698.4600 (+/- 1053.9529)\n```\n:::\n:::\n\n\nAll the code from before, the tokens and the debugging are replaced by a single \nimport that gives better results.\n\nThroughout the tutorial, we will see how each step can be simplified, replaced, or\nimproved using skrub features, going through the various features until we get to\nthe `tabular_pipeline`. \n\n## Roadmap for the course\nWe are going to build what could be a typicial pre-processing pipeline: \n\n1. We will explore the data to identify possible problems and figure out what needs\nto be cleaned.\n2. We will then sanitize the data to address some common problems. \n3. There will be an intermission on various skrub features that simplify.\n4. Then, we will show how to perform feature engineering using various skrub encoders.\n5. Finally, we will show how we can put everything together.\n\n",
    "supporting": [
      "00_intro_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js\" integrity=\"sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js\" integrity=\"sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}