{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Choose your column: selectors\"\n",
    "format:\n",
    "    revealjs:\n",
    "        slide-number: true\n",
    "        toc: true\n",
    "        code-fold: false\n",
    "        code-tools: true\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very often, column selection is more complex than simply passing a list of column\n",
    "names to a transformer: it may be necessary to select all columns that have a\n",
    "specific data type, or based on some other characteristic (presence of nulls,\n",
    "column cardinality etc.).\n",
    "\n",
    "The skrub `selectors` implement a number of selection strategies that can be \n",
    "combined in various ways to build complex filtering conditions that can then be \n",
    "employed by `ApplyToCols`, `ApplyToFrame`, `SelectCols` and `DropCols`. \n",
    "\n",
    "## Skrub selectors\n",
    "Selectors are available from the `skrub.selectors` namespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skrub.selectors as s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this example dataframe to test some of the selectors: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "data = {\n",
    "    \"int\": [15, 56, 63, 12, 44],\n",
    "    \"float\": [5.2, 2.4, 6.2, 10.45, 9.0],\n",
    "    \"str1\": [\"public\", \"private\", None, \"private\", \"public\"],\n",
    "    \"str2\": [\"officer\", \"manager\", \"lawyer\", \"chef\", \"teacher\"],\n",
    "    \"bool\": [True, False, True, False, True],\n",
    "    \"cat1\": pd.Categorical([\"yes\", \"yes\", None, \"yes\", \"no\"]),\n",
    "    \"cat2\": pd.Categorical([\"20K+\", \"40K+\", \"60K+\", \"30K+\", \"50K+\"]),\n",
    "    \"datetime-col\": [\n",
    "        datetime.datetime.fromisoformat(dt)\n",
    "        for dt in [\n",
    "            \"2020-02-03T12:30:05\",\n",
    "            \"2021-03-15T00:37:15\",\n",
    "            \"2022-02-13T17:03:25\",\n",
    "            \"2023-05-22T08:45:55\",\n",
    "        ]\n",
    "    ]\n",
    "    + [None],    }\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selectors should be used in conjunction with the transformers described in the \n",
    "previous chapter: `ApplyToCols`, `ApplyToFrame`, `SelectCols` and `DropCols`. \n",
    "\n",
    "Selectors allow to filter columns by data type:\n",
    "\n",
    "- `.float`: floating-point columns\n",
    "- `.integer`: integer columns\n",
    "- `.any_date`: date or datetime columns\n",
    "- `.boolean`: boolean columns\n",
    "- `.string`: columns with a String data type\n",
    "- `.categorical`: columns with a Categorical data type\n",
    "- `.numeric`: numeric (either integer or float) columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import SelectCols\n",
    "string_selector = s.string()\n",
    "\n",
    "SelectCols(cols=string_selector).fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional conditions include:\n",
    "\n",
    "- `.all`: select all columns\n",
    "- `.cardinality_below`: select all columns with a number of unique values lower\n",
    "than the given `threshold`\n",
    "- `.has_nulls`: select all columns that include at least one null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SelectCols(cols=s.has_nulls()).fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various selectors allow to choose columns based on their name: \n",
    "\n",
    "- `.cols`: choose the provided column name (or list of names)\n",
    "    - note that transformers that can accept selectors can also take column names\n",
    "    or lists of columns by default\n",
    "- `.glob`: use Unix shell style `glob` to select column names\n",
    "- `.regex`: select columns using regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SelectCols(cols=s.glob(\"cat*\")).fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining selectors\n",
    "\n",
    "Selectors can be inverted using `.inv` or the logical operator `~` to\n",
    "select all _other_ columns, and they can be combined using the `&` and `|`\n",
    "logical operators. It is also possible to remove from a selection with `-`:\n",
    "\n",
    "For example, to select all datetime columns OR all string columns that do not \n",
    "contain nulls, we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SelectCols(cols=(s.any_date() | (s.string()) & (~s.has_nulls()))).fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting selected columns\n",
    "Selectors can use the `expand` and `expand_index` methods to extract the columns\n",
    "that have been selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_nulls = s.has_nulls()\n",
    "has_nulls.expand(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be used, for example, to pass a list of columns to a dataframe library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=has_nulls.expand(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing custom filters\n",
    "Finally, it is possible to define function-based selectors using `.filter` and \n",
    "`.filter_names`. \n",
    "\n",
    "`.filter` selects columns for which the `predicate` evaluated by a user-defined\n",
    "function is `True`. \n",
    "For example,  it is possible to select columns that include a certain amount of \n",
    "nulls by defining a function like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import skrub.selectors as s\n",
    "from skrub import DropCols\n",
    "\n",
    "df = pd.DataFrame({\"a\": [None, None, None, 1], \"b\": [1,2,3,4]})\n",
    "\n",
    "def more_nulls_than(col, threshold=.5):\n",
    "    return col.isnull().sum()/len(col) > threshold\n",
    "\n",
    "DropCols(cols=s.filter(more_nulls_than, threshold=0.5)).fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.filter_names` is similar to `.filter` in the sense that it takes a function that\n",
    "returns a predicate, but in this case the function is evaluated over the column\n",
    "names. \n",
    "\n",
    "If we define this example dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import selectors as s\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"height_mm\": [297.0, 420.0],\n",
    "        \"width_mm\": [210.0, 297.0],\n",
    "        \"kind\": [\"A4\", \"A3\"],\n",
    "        \"ID\": [4, 3],\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select all the columns that end with `\"_mm\"` as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = s.filter_names(lambda name: name.endswith('_mm'))\n",
    "s.select(df, selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: using selectors together with `ApplyToCols`\n",
    "Consider this example dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"metric_1\": [10.5, 20.3, 30.1, 40.2],\n",
    "        \"metric_2\": [5.1, 15.6, None, 35.8],\n",
    "        \"metric_3\": [1.1, 3.3, 2.6, .8],\n",
    "        \"num_id\": [101, 102, 103, 104],\n",
    "        \"str_id\": [\"A101\", \"A102\", \"A103\", \"A104\"],\n",
    "        \"description\": [\"apple\", None, \"cherry\", \"date\"],\n",
    "        \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the skrub selectors and `ApplyToCols`:\n",
    "\n",
    "- Apply the `StandardScaler` to numeric columns, except `\"num_id\"`. \n",
    "- Apply a `OneHotEncoder` with `sparse_output=False` on all string columns except\n",
    "`\"str_id\"`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skrub.selectors as s\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from skrub import ApplyToCols\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Write your solution here\n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skrub.selectors as s\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from skrub import ApplyToCols\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "scaler = ApplyToCols(StandardScaler(), cols=s.numeric() - \"num_id\")\n",
    "one_hot = ApplyToCols(OneHotEncoder(sparse_output=False), cols=s.string() - \"str_id\")\n",
    "\n",
    "transformer = make_pipeline(scaler, one_hot)\n",
    "\n",
    "transformer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the same dataframe and using selectors, drop only string columns that contain\n",
    "nulls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import DropCols\n",
    "\n",
    "# Write your solution here\n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import DropCols\n",
    "\n",
    "DropCols(cols=s.has_nulls() & s.string()).fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write a custom function that selects columns where all values are lower than\n",
    "`10.0`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import SelectCols\n",
    "\n",
    "# Write your solution here\n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import SelectCols\n",
    "\n",
    "def lower_than(col):\n",
    "    return all(col < 10.0)\n",
    "\n",
    "SelectCols(cols=s.numeric() & s.filter(lower_than)).fit_transform(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3",
   "path": "/Users/rcap/work/skrub-tutorials/.pixi/envs/doc/share/jupyter/kernels/python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
