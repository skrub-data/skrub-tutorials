{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Scaling numerical features safely\"\n",
    "format:\n",
    "    revealjs:\n",
    "        slide-number: true\n",
    "        toc: true\n",
    "        code-fold: false\n",
    "        code-tools: true\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "Now that we can transform any column we want thanks to `ApplyToCols`, `ApplyToFrame` \n",
    "and the selectors, we can start covering the feature engineering part of our \n",
    "pipeline, beginning from numerical features. \n",
    "\n",
    "Specifically, we will find out how to safely scale numerical features with the \n",
    "skrub `SquashingScaler`.\n",
    "\n",
    "## Numerical features with outliers\n",
    "\n",
    "When dealing with numerical features that contain outliers (including infinite\n",
    "values), standard scaling methods can be problematic. Outliers can dramatically\n",
    "affect the centering and scaling of the entire dataset, causing the scaled inliers\n",
    "to be compressed into a narrow range.\n",
    "\n",
    "Consider this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import (\n",
    "    generate_data_with_outliers,\n",
    "    plot_feature_with_outliers\n",
    ")\n",
    "\n",
    "values = generate_data_with_outliers()\n",
    "\n",
    "plot_feature_with_outliers(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, most of the values are in the range `[-2, 2]`, but there are some \n",
    "large outliers in the range `[-40, 40]` that can cause issues when the feature \n",
    "needs to be scaled. \n",
    "\n",
    "\n",
    "### Regular scalers and their limitations\n",
    "\n",
    "The **StandardScaler** computes mean and standard deviation across all values.\n",
    "With outliers present, these statistics become unreliable, and the scaling factor\n",
    "can become too small, squashing inlier values.\n",
    "\n",
    "The **RobustScaler** uses quantiles (typically the 25th and 75th percentiles)\n",
    "instead of mean/std, which makes it more resistant to outliers. However, it\n",
    "doesn't bound the output values, so extreme outliers can still have very large\n",
    "scaled values.\n",
    "\n",
    "## SquashingScaler: A robust solution\n",
    "\n",
    "The `SquashingScaler` combines robust centering with smooth clipping to handle\n",
    "outliers effectively. It works in two stages:\n",
    "\n",
    "### Stage 1: Robust Scaling\n",
    "- Centers the median to zero\n",
    "- Scales using quantile-based statistics (by default, the interquartile range)\n",
    "- For columns where quantiles are equal, uses a custom MinMaxScaler\n",
    "- For columns with constant values, fills with zeros\n",
    "\n",
    "### Stage 2: Soft Clipping\n",
    "- Applies a smooth squashing function:\n",
    "$x_{\\text{out}} = \\frac{z}{\\sqrt{1 + (z/B)^2}}$\n",
    "- Constrains all values to the range\n",
    "$[-\\texttt{max\\_absolute\\_value}, \\texttt{max\\_absolute\\_value}]$ (default: 3)\n",
    "- Maps infinite values to the corresponding boundaries\n",
    "- Preserves NaN values unchanged\n",
    "\n",
    "### Advantages and disadvantages of `SquashingScaler`\n",
    "The `SquashingScaler` has various advantages over traditional scalers: \n",
    "\n",
    "- It is **Outlier-resistant**: Outliers don't affect inlier scaling, unlike the\n",
    "`StandardScaler`.\n",
    "- It has **Bounded output**: All values stay in a predictable range, ideal for \n",
    "neural networks and linear models.\n",
    "- It **Handles edge cases**: The scaler works with infinite values and constant \n",
    "columns.\n",
    "- It **Preserves missing data**: NaN values are kept unchanged. \n",
    "\n",
    "A disadvantage of the `SquashingScaler` is that it is**Non-invertible**: \n",
    "The soft clipping function is smooth but cannot be exactly inverted. \n",
    "\n",
    "## Conclusion\n",
    "\n",
    "When compared on data with outliers:\n",
    "\n",
    "- **StandardScaler** compresses inliers due to large scaling factors\n",
    "- **RobustScaler** preserves relative scales but allows extreme outlier values\n",
    "- **SquashingScaler** keeps inliers in a reasonable range while smoothly bounding\n",
    "all values\n",
    "\n",
    "If we plot the impact of each scaler on the result, this is what we can see: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import scale_feature_and_plot\n",
    "scale_feature_and_plot(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we showed how the `SquashingScaler` can be a better answer than\n",
    "traditional scalers when a numeric feature includes outliers. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3",
   "path": "/Users/rcap/work/skrub-tutorials/.pixi/envs/doc/share/jupyter/kernels/python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
