{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Exploring dataframes with skrub\"\n",
    "format:\n",
    "    revealjs:\n",
    "        slide-number: true\n",
    "        toc: true\n",
    "        code-fold: false\n",
    "        code-tools: true\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook, we will show how we use the skrub `TableReport` to explore\n",
    "tabular data. We will use the Adult Census dataset as our example table, and \n",
    "perform some exploratory analysis to learn about the characteristics of the data. \n",
    "\n",
    "First, let's import the necessary libraries and load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skrub import TableReport\n",
    "from sklearn.datasets import fetch_openml\n",
    "# Load the Adult Census dataset from OpenML\n",
    "adult = fetch_openml(name='adult', version=2, as_frame=True)\n",
    "data = adult.data\n",
    "target = adult.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a dataframe we can work with, we would like to find out:\n",
    "\n",
    "- The size of the dataset. \n",
    "- The data types and names of the columns. \n",
    "- The distribution of values in the columns. \n",
    "- Whether null values are present, in what measure and where. \n",
    "- Discrete/categorical features, and their cardinality.\n",
    "- Columns strongly correlated with each other. \n",
    "\n",
    "## Exploring data with Pandas tools\n",
    "For the sake of the example, let's first explore the data using Pandas only.\n",
    "\n",
    "We can get an idea of the content of the table by printing the first few lines, \n",
    "which gives an idea of the datatypes and the columns we are dealing with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to have a simpler view of the datatypes in the dataframe, we must \n",
    "use `data.info()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `.info()` we can find out the shape of the dataframe (the number of rows \n",
    "and columns), the datatype and the number of non-null values for each column. \n",
    "\n",
    "We can also get a richer summary of the data with the `.describe()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us useful information about all the features in the dataset. Among \n",
    "others, we can find the number of unique values in each column, various statistics\n",
    "for the numerical columns and the number of null values. \n",
    "\n",
    "## Exploring data with the `TableReport`\n",
    "\n",
    "Now, let's create a TableReport to explore the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TableReport(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default view of the TableReport\n",
    "The `TableReport` gives us a comprehensive overview of the dataset. The default\n",
    "view shows all the columns in the dataset, and allows to select and copy the content\n",
    "of the cells shown in the preview. \n",
    "\n",
    "The `TableReport` is intended to show a preview of the data, so it does not \n",
    "contain all the rows in the dataset, rather it shows only the first and last\n",
    "few rows by default. \n",
    "\n",
    "### The \"Stats\" tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TableReport(data, open_tab=\"stats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Stats\" tab provides a variety of descriptive statistics for each column in the dataset.\n",
    "This includes:\n",
    "\n",
    "- The column name\n",
    "- The detected data type of the column\n",
    "- Whether the column is sorted or not \n",
    "- The number of null values in the column, as well as the percentage\n",
    "- The number of unique values in the column\n",
    "\n",
    "For numerical columns, additional statistics are provided:\n",
    "\n",
    "- Mean\n",
    "- Standard deviation\n",
    "- Minimum and maximum values\n",
    "- Median\n",
    "\n",
    "### The \"Distributions\" tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TableReport(data, open_tab=\"distributions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Distributions\" tab provides visualizations of the distributions of values \n",
    "in each column. This includes histograms for numerical columns and bar plots for categorical columns.\n",
    "\n",
    "The \"Distributions\" tab helps with detecting potential issues in the data, such as:\n",
    "\n",
    "- Skewed distributions\n",
    "- Outliers\n",
    "- Unexpected value frequencies\n",
    "\n",
    "For example, in this dataset we can see that some columns are heavily \n",
    "skewed, such as \"workclass\", \"race\", and \"native-country\": this is important \n",
    "information to keep track of, because these columns may require special handling\n",
    "during data preprocessing or modeling.\n",
    "\n",
    "Additionally, the \"Distributions\" tab allows so select columns manually, so that\n",
    "they can be added to a script and selected for further analysis or modeling.\n",
    "\n",
    "::: {.callout-caution}\n",
    "The `TableReport` detects outliers using a simple interquartile test, marking \n",
    "as outliers all values that are beyond the IQR. This is a simple heuristic, and \n",
    "should not be treated as perfect. If your problem requires reliable outlier \n",
    "detection, you should not rely exclusively on what the `TableReport` shows. \n",
    ":::\n",
    "\n",
    "### The \"Associations\" tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TableReport(data, open_tab=\"associations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Associations\" tab provides insights into the relationships between different\n",
    "columns in the dataset.\n",
    "It shows Pearson's correlation coefficients for numerical columns, as well as\n",
    "Cramér's V for all columns. \n",
    "\n",
    "While this is a somewhat rough measure of association, it can help identify potential\n",
    "relationships worth exploring further during the analysis, and highlights \n",
    "highly correlated columns: depending on the modeling technique used, these may need \n",
    "to be handled specially to avoid issues with multicollinearity.\n",
    "\n",
    "In this example, we can see that \"education-num\" and \"education\" have perfect \n",
    "correlation, which means that one of the two columns can be dropped without losing\n",
    "information.\n",
    "\n",
    "## Exploring the target variable\n",
    "Let's take a closer look at the target variable, which indicates whether an individual's\n",
    "income exceeds $50K per year. We can create a separate `TableReport` for the target variable\n",
    "to explore its distribution: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TableReport(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring and saving the `TableReport` \n",
    "The `TableReport` can be saved on disk as an HTML. \n",
    "```{.python}\n",
    "TableReport(data).write_html(\"report.html\")\n",
    "```\n",
    "\n",
    "Then, the report can be opened using any internet browser, with no need to run \n",
    "a Jupyter notebok or a python interactive console. \n",
    "\n",
    "It is possible to configure various parameters using the skrub global config. \n",
    "For example, it is possible to replace the default Pandas or Polars dataframe display\n",
    "with the TableReport as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import set_config\n",
    "set_config(use_table_report=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with big tables\n",
    "Plotting and measuring the column correlations are expensive operations, so when \n",
    "the dataframe under study is large it may be more convenient to skip them, as \n",
    "generating the Distributions and Associations tab may take a long time.\n",
    "\n",
    "The `max_plot_columns` and `max_association_columns` parameters allow to set a \n",
    "threshold on the number of columns: the `TableReport` will skip the respective\n",
    "task if the number of colums in the dataframe is larger than the threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TableReport(data, max_association_columns=3, max_plot_columns=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the number of columns is too large, an error message is shown in the respective\n",
    "tab instead of the plots or correlations. \n",
    "\n",
    "# Exercise: exploring a new table\n",
    "For this exercise, we will use the `employee_salaries` dataframe to answer some \n",
    "questions. \n",
    "\n",
    "Run the following code to import the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub.datasets import fetch_employee_salaries\n",
    "\n",
    "employee_salaries = fetch_employee_salaries()\n",
    "data = employee_salaries.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the skrub `TableReport` and answer the following questions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TableReport(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "- What's the size of the dataframe? (columns and rows)\n",
    "- How many columns have object/numerical/datetime\n",
    "- Are there columns with a large number of missing values?\n",
    "- Are there columns that have a high cardinality (>40 unique values)?\n",
    "- Were datetime columns parsed correctly?\n",
    "- Which columns have outliers?\n",
    "- Which columns have an imbalanced distribution?\n",
    "- Which columns are strongly correlated with each other?\n",
    "\n",
    "\n",
    "### Answers\n",
    "- What's the size of the dataframe? (columns and rows)\n",
    "    - 9228 rows × 8 columns\n",
    "- How many columns have object/numerical/datetime\n",
    "    - No datetime columns, one integer column (`year_first_hired`), all other columns\n",
    "    are objects. \n",
    "- Are there columns with a large number of missing values?\n",
    "    - No, only the `gender` column contains a small fraction (0.2%) of missing\n",
    "    values.\n",
    "- Are there columns that have a high cardinality?\n",
    "    - Yes, `division`, `employee_position_title`, `date_first_hired` have a \n",
    "    cardinality larger than 40. \n",
    "- Were datetime columns parsed correctly?\n",
    "    - No, the `date_first_hired` column has dtype Object. \n",
    "- Which columns have outliers?\n",
    "    - No columns seem to include outliers. \n",
    "- Which columns have an imbalanced distribution?\n",
    "    - `assignment_category` has an unbalanced distribution. \n",
    "- Which columns are strongly correlated with each other?\n",
    "    - `department` and `department_name` have a Cramer's V of 1, so they are \n",
    "    very strongly correlated. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
