{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Building a tabular pipeline\"\n",
    "format:\n",
    "    revealjs:\n",
    "        slide-number: true\n",
    "        toc: true\n",
    "        code-fold: false\n",
    "        code-tools: true\n",
    "\n",
    "---\n",
    "\n",
    "1. pipeline with `TableVectorizer`\n",
    "2. pipeline with `tabular_pipeline`\n",
    "\n",
    "We can now put data cleaning and feature engineering together to build a full\n",
    "machine learning pipeline. \n",
    "\n",
    "## Exercise: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub.datasets import fetch_employee_salaries\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "adult = fetch_openml(\"adult\", version=2)  \n",
    "X = adult.data\n",
    "y = adult.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "categorical_columns = selector(dtype_include=\"category\")(X)\n",
    "numerical_columns = selector(dtype_include=\"number\")(X)\n",
    "\n",
    "ct = make_column_transformer(\n",
    "      (StandardScaler(),\n",
    "       numerical_columns),\n",
    "      (OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "       categorical_columns))\n",
    "\n",
    "model_base = make_pipeline(ct, SimpleImputer(), LogisticRegression())\n",
    "model_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import TableVectorizer\n",
    "\n",
    "tv = TableVectorizer()\n",
    "\n",
    "model_tv = make_pipeline(tv, SimpleImputer(), StandardScaler(), LogisticRegression())\n",
    "model_tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import tabular_pipeline\n",
    "\n",
    "model_tp = tabular_pipeline(LogisticRegression())\n",
    "model_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hgb = tabular_pipeline(\"classification\")\n",
    "model_hgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "results_base = cross_val_score(model_base, X, y)\n",
    "print(f\"Base model: {results_base.mean():.4f}\")\n",
    "\n",
    "results_tv = cross_val_score(model_tv, X, y)\n",
    "print(f\"TableVectorizer: {results_tv.mean():.4f}\")\n",
    "\n",
    "results_tp = cross_val_score(model_tp, X, y)\n",
    "print(f\"Tabular pipeline: {results_tp.mean():.4f}\")\n",
    "\n",
    "results_hgb = cross_val_score(model_hgb, X, y)\n",
    "print(f\"HGB model: {results_hgb.mean():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3",
   "path": "/Users/rcap/work/skrub-tutorials/.pixi/envs/doc/share/jupyter/kernels/python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
