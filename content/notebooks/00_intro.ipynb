{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"A world without skrub\"\n",
    "format:\n",
    "    revealjs:\n",
    "        slide-number: true\n",
    "        toc: true\n",
    "        code-fold: false\n",
    "        code-tools: true\n",
    "\n",
    "---\n",
    "\n",
    "Let's begin the lesson by imagining a world without skrub, where we can use \n",
    "only Pandas and scikit-learn to clean data and prepare a machine learning model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skrub.datasets import fetch_employee_salaries\n",
    "\n",
    "data = fetch_employee_salaries()\n",
    "X, y = data.X, data.y\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the target::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a numerical column, and our task is predicting the value of `current_annual_salary`.\n",
    "\n",
    "## Strategizing\n",
    "We can begin by exploring the dataframe with `.describe`, and then think of a \n",
    "plan for pre-processing our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to:\n",
    "\n",
    "- Impute some missing values in the `gender` column.\n",
    "- Encode convert categorical features into numerical features. \n",
    "- Convert the column `date_first_hired` into numerical features.\n",
    "\n",
    "Once we have processed the data, we can train a machine learning model. For the sake\n",
    "of the example, we will use a linear model (`Ridge`), which means that we need to scale numerical features, besides imputing missing values. \n",
    "\n",
    "Finally, we want to evaluate the performance of the method across multiple \n",
    "cross-validation splits.\n",
    "\n",
    "## Building a traditional pipeline\n",
    "Let's build a traditional predictive pipeline following the steps we just discussed. \n",
    "\n",
    "### Step 1: Convert date features to numerical\n",
    "\n",
    "Extract numerical features from the `date_first_hired` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy to work with\n",
    "X_processed = X.copy()\n",
    "\n",
    "# Parse the date column\n",
    "X_processed['date_first_hired'] = pd.to_datetime(X_processed['date_first_hired'])\n",
    "\n",
    "# Extract numerical features from date\n",
    "X_processed['years_since_hired'] = (pd.Timestamp.now() - X_processed['date_first_hired']).dt.days / 365.25\n",
    "X_processed['hired_month'] = X_processed['date_first_hired'].dt.month\n",
    "X_processed['hired_year'] = X_processed['date_first_hired'].dt.year\n",
    "\n",
    "# Drop original date column\n",
    "X_processed = X_processed.drop('date_first_hired', axis=1)\n",
    "\n",
    "print(\"Features after date transformation:\")\n",
    "print(\"\\nShape:\", X_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Encode categorical features\n",
    "\n",
    "Encode only the non-numerical categorical features using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify only the non-numerical (truly categorical) columns\n",
    "categorical_cols = X_processed.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"Categorical columns to encode:\", categorical_cols)\n",
    "\n",
    "# Apply one-hot encoding only to categorical columns\n",
    "X_encoded = pd.get_dummies(X_processed, columns=categorical_cols)\n",
    "print(\"\\nShape after encoding:\", X_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Impute missing values\n",
    "\n",
    "We'll impute missing values in the `gender` column using the most frequent strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute missing values with most frequent value\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "X_encoded_imputed = pd.DataFrame(\n",
    "    imputer.fit_transform(X_encoded),\n",
    "    columns=X_encoded.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Scale numerical features\n",
    "\n",
    "Scale numerical features for the Ridge regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "X_scaled = scaler.fit_transform(X_encoded_imputed)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X_encoded_imputed.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Train Ridge model with cross-validation\n",
    "\n",
    "Train a Ridge regression model and evaluate with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Ridge model\n",
    "ridge = Ridge(alpha=1.0)\n",
    "\n",
    "# Perform cross-validation (5-fold)\n",
    "cv_results = cross_validate(ridge, X_scaled, y, cv=5, \n",
    "                            scoring=['r2', 'neg_mean_squared_error'],\n",
    "                            return_train_score=True)\n",
    "\n",
    "# Convert MSE to RMSE\n",
    "train_rmse = np.sqrt(-cv_results['train_neg_mean_squared_error'])\n",
    "test_rmse = np.sqrt(-cv_results['test_neg_mean_squared_error'])\n",
    "\n",
    "# Display results\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(f\"Mean test R²: {cv_results['test_r2'].mean():.4f} (+/- {cv_results['test_r2'].std():.4f})\")\n",
    "print(f\"Mean test RMSE: {test_rmse.mean():.4f} (+/- {test_rmse.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Just ask an agent to write the code\"\n",
    "It's what I did. Here are some of the issues I noticed: \n",
    "\n",
    "- Operations in the wrong order.\n",
    "- Trying to impute categorical features without encoding them as numerical values.\n",
    "- The datetime feature was encoded as a categorical (i.e, with dummmies).\n",
    "- Too many print statements.\n",
    "- Cells could not be executed in order without proper debugging and re-prompting.\n",
    "\n",
    "\n",
    "## Waking up from a nightmare\n",
    "Thankfully, we live in a world where we can `import skrub`. Let's see what we can\n",
    "get if we use `skrub.tabular_pipeline`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import tabular_pipeline\n",
    "\n",
    "# Perform cross-validation (5-fold)\n",
    "cv_results = cross_validate(tabular_pipeline(\"regression\"), X, y, cv=5, \n",
    "                            scoring=['r2', 'neg_mean_squared_error'],\n",
    "                            return_train_score=True)\n",
    "\n",
    "# Convert MSE to RMSE\n",
    "train_rmse = np.sqrt(-cv_results['train_neg_mean_squared_error'])\n",
    "test_rmse = np.sqrt(-cv_results['test_neg_mean_squared_error'])\n",
    "\n",
    "# Display results\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(f\"Mean test R²: {cv_results['test_r2'].mean():.4f} (+/- {cv_results['test_r2'].std():.4f})\")\n",
    "print(f\"Mean test RMSE: {test_rmse.mean():.4f} (+/- {test_rmse.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the code from before, the tokens and the debugging are replaced by a single \n",
    "import that gives better results.\n",
    "\n",
    "Throughout the tutorial, we will see how each step can be simplified, replaced, or\n",
    "improved using skrub features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3",
   "path": "/Users/rcap/work/skrub-tutorials/.pixi/envs/doc/share/jupyter/kernels/python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
