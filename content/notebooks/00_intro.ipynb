{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"A world without skrub\"\n",
    "format:\n",
    "    revealjs:\n",
    "        slide-number: true\n",
    "        toc: true\n",
    "        code-fold: false\n",
    "        code-tools: true\n",
    "\n",
    "---\n",
    "\n",
    "Let's begin the lesson by imagining a world without skrub, where we can use \n",
    "only Pandas and scikit-learn to clean data and prepare a machine learning model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skrub.datasets import fetch_employee_salaries\n",
    "\n",
    "data = fetch_employee_salaries()\n",
    "X, y = data.X, data.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the target::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        69222.18\n",
       "1        97392.47\n",
       "2       104717.28\n",
       "3        52734.57\n",
       "4        93396.00\n",
       "          ...    \n",
       "9223     72094.53\n",
       "9224    169543.85\n",
       "9225    102736.52\n",
       "9226    153747.50\n",
       "9227     75484.08\n",
       "Name: current_annual_salary, Length: 9228, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a numerical column, and our task is predicting the value of `current_annual_salary`.\n",
    "\n",
    "## Strategizing\n",
    "We can begin by exploring the dataframe with `.describe`, and then think of a \n",
    "plan for pre-processing our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>department</th>\n",
       "      <th>department_name</th>\n",
       "      <th>division</th>\n",
       "      <th>assignment_category</th>\n",
       "      <th>employee_position_title</th>\n",
       "      <th>date_first_hired</th>\n",
       "      <th>year_first_hired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9211</td>\n",
       "      <td>9228</td>\n",
       "      <td>9228</td>\n",
       "      <td>9228</td>\n",
       "      <td>9228</td>\n",
       "      <td>9228</td>\n",
       "      <td>9228</td>\n",
       "      <td>9228.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>694</td>\n",
       "      <td>2</td>\n",
       "      <td>443</td>\n",
       "      <td>2264</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>M</td>\n",
       "      <td>POL</td>\n",
       "      <td>Department of Police</td>\n",
       "      <td>School Health Services</td>\n",
       "      <td>Fulltime-Regular</td>\n",
       "      <td>Bus Operator</td>\n",
       "      <td>12/12/2016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5481</td>\n",
       "      <td>1844</td>\n",
       "      <td>1844</td>\n",
       "      <td>300</td>\n",
       "      <td>8394</td>\n",
       "      <td>638</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003.597529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.327078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1965.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1998.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender department       department_name                division  \\\n",
       "count    9211       9228                  9228                    9228   \n",
       "unique      2         37                    37                     694   \n",
       "top         M        POL  Department of Police  School Health Services   \n",
       "freq     5481       1844                  1844                     300   \n",
       "mean      NaN        NaN                   NaN                     NaN   \n",
       "std       NaN        NaN                   NaN                     NaN   \n",
       "min       NaN        NaN                   NaN                     NaN   \n",
       "25%       NaN        NaN                   NaN                     NaN   \n",
       "50%       NaN        NaN                   NaN                     NaN   \n",
       "75%       NaN        NaN                   NaN                     NaN   \n",
       "max       NaN        NaN                   NaN                     NaN   \n",
       "\n",
       "       assignment_category employee_position_title date_first_hired  \\\n",
       "count                 9228                    9228             9228   \n",
       "unique                   2                     443             2264   \n",
       "top       Fulltime-Regular            Bus Operator       12/12/2016   \n",
       "freq                  8394                     638               87   \n",
       "mean                   NaN                     NaN              NaN   \n",
       "std                    NaN                     NaN              NaN   \n",
       "min                    NaN                     NaN              NaN   \n",
       "25%                    NaN                     NaN              NaN   \n",
       "50%                    NaN                     NaN              NaN   \n",
       "75%                    NaN                     NaN              NaN   \n",
       "max                    NaN                     NaN              NaN   \n",
       "\n",
       "        year_first_hired  \n",
       "count        9228.000000  \n",
       "unique               NaN  \n",
       "top                  NaN  \n",
       "freq                 NaN  \n",
       "mean         2003.597529  \n",
       "std             9.327078  \n",
       "min          1965.000000  \n",
       "25%          1998.000000  \n",
       "50%          2005.000000  \n",
       "75%          2012.000000  \n",
       "max          2016.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to:\n",
    "\n",
    "- Impute some missing values in the `gender` column.\n",
    "- Encode convert categorical features into numerical features. \n",
    "- Convert the column `date_first_hired` into numerical features.\n",
    "\n",
    "Once we have processed the data, we can train a machine learning model. For the sake\n",
    "of the example, we will use a linear model (`Ridge`), which means that we need to scale numerical features, besides imputing missing values. \n",
    "\n",
    "Finally, we want to evaluate the performance of the method across multiple \n",
    "cross-validation splits.\n",
    "\n",
    "## Building a traditional pipeline\n",
    "Let's build a traditional predictive pipeline following the steps we just discussed. \n",
    "\n",
    "### Step 1: Convert date features to numerical\n",
    "\n",
    "Extract numerical features from the `date_first_hired` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features after date transformation:\n",
      "\n",
      "Shape: (9228, 10)\n"
     ]
    }
   ],
   "source": [
    "# Create a copy to work with\n",
    "X_processed = X.copy()\n",
    "\n",
    "# Parse the date column\n",
    "X_processed['date_first_hired'] = pd.to_datetime(X_processed['date_first_hired'])\n",
    "\n",
    "# Extract numerical features from date\n",
    "X_processed['years_since_hired'] = (pd.Timestamp.now() - X_processed['date_first_hired']).dt.days / 365.25\n",
    "X_processed['hired_month'] = X_processed['date_first_hired'].dt.month\n",
    "X_processed['hired_year'] = X_processed['date_first_hired'].dt.year\n",
    "\n",
    "# Drop original date column\n",
    "X_processed = X_processed.drop('date_first_hired', axis=1)\n",
    "\n",
    "print(\"Features after date transformation:\")\n",
    "print(\"\\nShape:\", X_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Encode categorical features\n",
    "\n",
    "Encode only the non-numerical categorical features using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns to encode: ['gender', 'department', 'department_name', 'division', 'assignment_category', 'employee_position_title']\n",
      "\n",
      "Shape after encoding: (9228, 1219)\n"
     ]
    }
   ],
   "source": [
    "# Identify only the non-numerical (truly categorical) columns\n",
    "categorical_cols = X_processed.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"Categorical columns to encode:\", categorical_cols)\n",
    "\n",
    "# Apply one-hot encoding only to categorical columns\n",
    "X_encoded = pd.get_dummies(X_processed, columns=categorical_cols)\n",
    "print(\"\\nShape after encoding:\", X_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Impute missing values\n",
    "\n",
    "We'll impute missing values in the `gender` column using the most frequent strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute missing values with most frequent value\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "X_encoded_imputed = pd.DataFrame(\n",
    "    imputer.fit_transform(X_encoded),\n",
    "    columns=X_encoded.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Scale numerical features\n",
    "\n",
    "Scale numerical features for the Ridge regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "X_scaled = scaler.fit_transform(X_encoded_imputed)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X_encoded_imputed.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Train Ridge model with cross-validation\n",
    "\n",
    "Train a Ridge regression model and evaluate with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results:\n",
      "Mean test R²: 0.8722 (+/- 0.0274)\n",
      "Mean test RMSE: 10366.9520 (+/- 1403.5225)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Ridge model\n",
    "ridge = Ridge(alpha=1.0)\n",
    "\n",
    "# Perform cross-validation (5-fold)\n",
    "cv_results = cross_validate(ridge, X_scaled, y, cv=5, \n",
    "                            scoring=['r2', 'neg_mean_squared_error'],\n",
    "                            return_train_score=True)\n",
    "\n",
    "# Convert MSE to RMSE\n",
    "train_rmse = np.sqrt(-cv_results['train_neg_mean_squared_error'])\n",
    "test_rmse = np.sqrt(-cv_results['test_neg_mean_squared_error'])\n",
    "\n",
    "# Display results\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(f\"Mean test R²: {cv_results['test_r2'].mean():.4f} (+/- {cv_results['test_r2'].std():.4f})\")\n",
    "print(f\"Mean test RMSE: {test_rmse.mean():.4f} (+/- {test_rmse.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Just ask an agent to write the code\"\n",
    "It's what I did. Here are some of the issues I noticed: \n",
    "\n",
    "- Operations in the wrong order.\n",
    "- Trying to impute categorical features without encoding them as numerical values.\n",
    "- The datetime feature was encoded as a categorical (i.e, with dummmies).\n",
    "- Too many print statements.\n",
    "- Cells could not be executed in order without proper debugging and re-prompting.\n",
    "\n",
    "\n",
    "## Waking up from a nightmare\n",
    "Thankfully, we live in a world where we can `import skrub`. Let's see what we can\n",
    "get if we use `skrub.tabular_pipeline`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results:\n",
      "Mean test R²: 0.9083 (+/- 0.0166)\n",
      "Mean test RMSE: 8802.3781 (+/- 1060.9218)\n"
     ]
    }
   ],
   "source": [
    "from skrub import tabular_pipeline\n",
    "\n",
    "# Perform cross-validation (5-fold)\n",
    "cv_results = cross_validate(tabular_pipeline(\"regression\"), X, y, cv=5, \n",
    "                            scoring=['r2', 'neg_mean_squared_error'],\n",
    "                            return_train_score=True)\n",
    "\n",
    "# Convert MSE to RMSE\n",
    "train_rmse = np.sqrt(-cv_results['train_neg_mean_squared_error'])\n",
    "test_rmse = np.sqrt(-cv_results['test_neg_mean_squared_error'])\n",
    "\n",
    "# Display results\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(f\"Mean test R²: {cv_results['test_r2'].mean():.4f} (+/- {cv_results['test_r2'].std():.4f})\")\n",
    "print(f\"Mean test RMSE: {test_rmse.mean():.4f} (+/- {test_rmse.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the code from before, the tokens and the debugging are replaced by a single \n",
    "import that gives better results.\n",
    "\n",
    "Throughout the tutorial, we will see how each step can be simplified, replaced, or\n",
    "improved using skrub features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
