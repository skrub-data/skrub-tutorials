{
  "hash": "26217cc4a69102871fc47e443684fbac",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Applying transformers to columns\"\nformat:\n    html:\n        toc: true\n    revealjs:\n        slide-number: true\n        toc: false\n        code-fold: false\n        code-tools: true\n\n---\n\n## Introduction\nOften, transformers need to be applied only to a subset of columns, rather than \nthe entire dataframe. \n\nAs an example, it does not make sense to apply a `StandardScaler` to a column \nthat contains strings, and indeed doing so would raise an exception. \nIn other cases, specific columns may need particular treatment, and should therefore\nbe ignored by the `Cleaner`. \n\nScikit-learn provides the `ColumnTransformer` to deal with this: \n\n::: {#de95f037 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nfrom sklearn.compose import make_column_selector as selector\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\n\ndf = pd.DataFrame({\"text\": [\"foo\", \"bar\", \"baz\"], \"number\": [1, 2, 3]})\n\ncategorical_columns = selector(dtype_include=object)(df)\nnumerical_columns = selector(dtype_exclude=object)(df)\n\nct = make_column_transformer(\n      (StandardScaler(),\n       numerical_columns),\n      (OneHotEncoder(handle_unknown=\"ignore\"),\n       categorical_columns))\ntransformed = ct.fit_transform(df)\ntransformed\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\narray([[-1.22474487,  0.        ,  0.        ,  1.        ],\n       [ 0.        ,  1.        ,  0.        ,  0.        ],\n       [ 1.22474487,  0.        ,  1.        ,  0.        ]])\n```\n:::\n:::\n\n\n`make_column_selector` allows to choose columns based on their datatype, or by \nusing regex to filter column names. In some cases, this degree of control is \nnot sufficient. \n\nTo address such situations, skrub implements different transformers that allow \nto modify columns from within scikit-learn pipelines. Additionally, the selectors\nAPI allows to implement powerful, custom-made column selection filters. \n\n`SelectCols` and `DropCols` are transformers that can be used as part of a \npipeline to filter columns according to the selectors API, while `ApplyToCols` and\n`ApplyToFrame` replicate the `ColumnTransformer` behavior with a different syntax\nand access to the selectors. \n\n## Selection operations in a scikit-learn pipeline\n`SelectCols` and `DropCols` allow selecting or removing specific columns in a \ndataframe according to user-provided rules. For example, to remove columns that \ninclude null values, or to select only columns that have a specific dtype. \n\n`SelectCols` and `DropCols` take a `cols` parameter to choose which columns to \nselect or drop respectively.\n\n::: {#a977c024 .cell execution_count=2}\n``` {.python .cell-code}\nfrom skrub import ToDatetime\ndf = pd.DataFrame({\n    \"date\": [\"03 January 2023\", \"04 February 2023\", \"05 March 2023\"],\n    \"values\": [10, 20, 30]\n})\ndf\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>values</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>03 January 2023</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>04 February 2023</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>05 March 2023</td>\n      <td>30</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWe can selectively choose or drop columns based on names, or more complex rules \n(see the next chapter).\n\n::: {#6a1bbb91 .cell execution_count=3}\n``` {.python .cell-code}\nfrom skrub import SelectCols\nSelectCols(\"date\").fit_transform(df)\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>03 January 2023</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>04 February 2023</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>05 March 2023</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#5c780f35 .cell execution_count=4}\n``` {.python .cell-code}\nfrom skrub import DropCols\nDropCols(\"date\").fit_transform(df)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>values</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## `ApplyToCols` and `ApplyToFrame`\nBesides selecting and dropping columns, pre-processing pipelines are intended to \n_transform_ specific columns in specific ways. To make this process easier, skrub \nprovides the `ApplyToCols` and `ApplyToFrame` transformers.\n\n### Applying a transformer to separate columns: `ApplyToCols`\nIn many cases, `ApplyToCols` can be a direct replacememnt for the `ColumnTransformer`,\nlike in the following example:\n\n::: {#777b8f90 .cell execution_count=5}\n``` {.python .cell-code}\nimport skrub.selectors as s\nfrom sklearn.pipeline import make_pipeline\nfrom skrub import ApplyToCols\n\nnumeric = ApplyToCols(StandardScaler(), cols=s.numeric())\nstring = ApplyToCols(OneHotEncoder(sparse_output=False), cols=s.string())\n\ntransformed = make_pipeline(numeric, string).fit_transform(df)\ntransformed\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_03 January 2023</th>\n      <th>date_04 February 2023</th>\n      <th>date_05 March 2023</th>\n      <th>values</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.224745</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.224745</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nIn this case, we are applying the `StandardScaler` only to numeric features using \n`s.numeric()`, and `OneHotEncoder` with `s.string()`. \n\nUnder the hood, `ApplyToCol` selects all columns that satisfy the condition specified\nin `cols` (in this case, that the dtype is numeric), then clones and applies the\nspecified transformer (`StandardScaler`) to each column _separately_. \n\n::: {.callout-important}\nColumns that are not selected are passed through without any change, thus string\ncolumns are not touched by the `numeric` transformer. \n:::\n\nBy passing through unselected columns without changes it is possible to chain \nseveral `ApplyToCols` together by putting them in a scikit-learn pipeline. \n\n::: {.callout-important}\n`ApplyToCols` is intended to work on dataframes, which are **dense**. As a result,\ntransformers that produce sparse outputs (like the `OneHotEncoder`) must be set \nso that their output is dense. \n:::\n\n\n### Applying the same transformer to multiple columns at once: `ApplyToFrame`\nIn some cases, there may be a need to apply the same transformer only to a subset \nof columns in a dataframe. \n\nConsider this example dataframe, which some patient information, and some metrics. \n\n::: {#32ce9b4e .cell execution_count=6}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\n\nn_patients = 20\nnp.random.seed(42)\ndf = pd.DataFrame({\n    \"patient_id\": [f\"P{i:03d}\" for i in range(n_patients)],\n    \"age\": np.random.randint(18, 80, size=n_patients),\n    \"sex\": np.random.choice([\"M\", \"F\"], size=n_patients),\n})\n\nfor i in range(5):\n    df[f\"metric_{i}\"] = np.random.normal(loc=50, scale=10, size=n_patients)\n\ndf[\"diagnosis\"] = np.random.choice([\"A\", \"B\", \"C\"], size=n_patients)\ndf.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_id</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>metric_0</th>\n      <th>metric_1</th>\n      <th>metric_2</th>\n      <th>metric_3</th>\n      <th>metric_4</th>\n      <th>diagnosis</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>P000</td>\n      <td>56</td>\n      <td>F</td>\n      <td>39.871689</td>\n      <td>52.088636</td>\n      <td>41.607825</td>\n      <td>50.870471</td>\n      <td>52.961203</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>P001</td>\n      <td>69</td>\n      <td>M</td>\n      <td>53.142473</td>\n      <td>30.403299</td>\n      <td>46.907876</td>\n      <td>47.009926</td>\n      <td>52.610553</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>P002</td>\n      <td>46</td>\n      <td>F</td>\n      <td>40.919759</td>\n      <td>36.718140</td>\n      <td>53.312634</td>\n      <td>50.917608</td>\n      <td>50.051135</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>P003</td>\n      <td>32</td>\n      <td>F</td>\n      <td>35.876963</td>\n      <td>51.968612</td>\n      <td>59.755451</td>\n      <td>30.124311</td>\n      <td>47.654129</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>P004</td>\n      <td>60</td>\n      <td>F</td>\n      <td>64.656488</td>\n      <td>57.384666</td>\n      <td>45.208258</td>\n      <td>47.803281</td>\n      <td>35.846293</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWith `ApplyToFrame`, it is easy to apply a decomposition algorithm such as `PCA` \nto condense the `metric_*` columns into a smaller number of features: \n\n::: {#4f5cf7e4 .cell execution_count=7}\n``` {.python .cell-code}\nfrom skrub import ApplyToFrame\nfrom sklearn.decomposition import PCA\n\nreduce = ApplyToFrame(PCA(n_components=2), cols=s.glob(\"metric_*\"))\n\ndf_reduced = reduce.fit_transform(df)\ndf_reduced.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_id</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>diagnosis</th>\n      <th>pca0</th>\n      <th>pca1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>P000</td>\n      <td>56</td>\n      <td>F</td>\n      <td>B</td>\n      <td>-2.647377</td>\n      <td>7.025046</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>P001</td>\n      <td>69</td>\n      <td>M</td>\n      <td>A</td>\n      <td>-2.480564</td>\n      <td>-11.246997</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>P002</td>\n      <td>46</td>\n      <td>F</td>\n      <td>B</td>\n      <td>4.274840</td>\n      <td>-5.039065</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>P003</td>\n      <td>32</td>\n      <td>F</td>\n      <td>B</td>\n      <td>14.116747</td>\n      <td>15.620615</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>P004</td>\n      <td>60</td>\n      <td>F</td>\n      <td>C</td>\n      <td>-19.073862</td>\n      <td>1.186541</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### The `allow_reject` parameter\nWhen `ApplyToCols` or `ApplyToFrame` are using a skrub transformer, they can use\nthe `allow_reject` parameter for more flexibility. By setting `allow_reject` to \n`True`, columns that cannot be treated by the current transformer will be ignored\nrather than raising an exception. \n\nConsider this example. By default, `ToDatetime` raises a `RejectColumn` exception\nwhen it finds a column it cannot convert to datetime. \n\n::: {#4f3256f3 .cell execution_count=8}\n``` {.python .cell-code}\nfrom skrub import ToDatetime\ndf = pd.DataFrame({\n    \"date\": [\"03 January 2023\", \"04 February 2023\", \"05 March 2023\"],\n    \"values\": [10, 20, 30]\n})\ndf\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>values</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>03 January 2023</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>04 February 2023</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>05 March 2023</td>\n      <td>30</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nBy setting `allow_reject=True`, the datetime column is converted properly and \nthe other column is passed through without issues. \n\n::: {#88262861 .cell execution_count=9}\n``` {.python .cell-code}\nwith_reject = ApplyToCols(ToDatetime(), allow_reject=True)\nwith_reject.fit_transform(df)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>values</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023-01-03</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2023-02-04</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2023-03-05</td>\n      <td>30</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Concatenating the skrub column transformers\nSkrub column transformers can be concatenated by using scikit-learn pipelines.\nIn the following example, we first select only the column `patient_id`, then encode\nit using `OneHotEncoder` and finally use `PCA` to reduce the number of dimensions.\n\nThis is done by wrapping the latter two steps in `ApplyToCols` and `ApplyToFrame` \nrespectively, and then putting all transformers in order in a scikit-learn pipeline\nusing `make_pipeline`. \n\n::: {#49387eab .cell execution_count=10}\n``` {.python .cell-code}\nfrom sklearn.pipeline import make_pipeline\nfrom skrub import SelectCols\n\ndf = pd.DataFrame({\n    \"patient_id\": [f\"P{i:03d}\" for i in range(n_patients)],\n    \"age\": np.random.randint(18, 80, size=n_patients),\n    \"sex\": np.random.choice([\"M\", \"F\"], size=n_patients),\n})\n\nselect = SelectCols(\"patient_id\")\nencode = ApplyToCols(OneHotEncoder(sparse_output=False))\nreduce = ApplyToFrame(PCA(n_components=2))\n\ntransform = make_pipeline(select, encode, reduce)\ndft= transform.fit_transform(df)\ndft.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pca0</th>\n      <th>pca1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.451188e-17</td>\n      <td>9.393890e-18</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-2.405452e-02</td>\n      <td>9.397337e-01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-2.305851e-01</td>\n      <td>9.374222e-03</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-5.287468e-02</td>\n      <td>9.374222e-03</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-7.954573e-02</td>\n      <td>-6.807817e-03</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### The order of column transformations is important\nSome care must be taken when concatenating columnn transformers, in particular\nwhen selection is done on datatypes. Consider this case:\n\n::: {#e74fa56b .cell execution_count=11}\n``` {.python .cell-code}\nencode = ApplyToCols(OneHotEncoder(sparse_output=False), cols=s.string())\nscale = ApplyToCols(StandardScaler(), cols=s.numeric())\n```\n:::\n\n\nIn the first case, we encode and then scale, in the second case we instead \nscale first and then encode. \n\n::: {#fb479800 .cell execution_count=12}\n``` {.python .cell-code}\ntransform_1 = make_pipeline(encode, scale)\ndft = transform_1.fit_transform(df)\ndft.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_id_P000</th>\n      <th>patient_id_P001</th>\n      <th>patient_id_P002</th>\n      <th>patient_id_P003</th>\n      <th>patient_id_P004</th>\n      <th>patient_id_P005</th>\n      <th>patient_id_P006</th>\n      <th>patient_id_P007</th>\n      <th>patient_id_P008</th>\n      <th>patient_id_P009</th>\n      <th>...</th>\n      <th>patient_id_P013</th>\n      <th>patient_id_P014</th>\n      <th>patient_id_P015</th>\n      <th>patient_id_P016</th>\n      <th>patient_id_P017</th>\n      <th>patient_id_P018</th>\n      <th>patient_id_P019</th>\n      <th>age</th>\n      <th>sex_F</th>\n      <th>sex_M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4.358899</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>...</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-1.301570</td>\n      <td>0.904534</td>\n      <td>-0.904534</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.229416</td>\n      <td>4.358899</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>...</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.709947</td>\n      <td>0.904534</td>\n      <td>-0.904534</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>4.358899</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>...</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>0.059162</td>\n      <td>-1.105542</td>\n      <td>1.105542</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>4.358899</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>...</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-1.479057</td>\n      <td>-1.105542</td>\n      <td>1.105542</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>4.358899</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>...</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.229416</td>\n      <td>-0.473298</td>\n      <td>0.904534</td>\n      <td>-0.904534</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 23 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {#496abdc6 .cell execution_count=13}\n``` {.python .cell-code}\ntransform_2 = make_pipeline(scale, encode)\ndft = transform_2.fit_transform(df)\ndft.head(5)\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patient_id_P000</th>\n      <th>patient_id_P001</th>\n      <th>patient_id_P002</th>\n      <th>patient_id_P003</th>\n      <th>patient_id_P004</th>\n      <th>patient_id_P005</th>\n      <th>patient_id_P006</th>\n      <th>patient_id_P007</th>\n      <th>patient_id_P008</th>\n      <th>patient_id_P009</th>\n      <th>...</th>\n      <th>patient_id_P013</th>\n      <th>patient_id_P014</th>\n      <th>patient_id_P015</th>\n      <th>patient_id_P016</th>\n      <th>patient_id_P017</th>\n      <th>patient_id_P018</th>\n      <th>patient_id_P019</th>\n      <th>age</th>\n      <th>sex_F</th>\n      <th>sex_M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.301570</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.709947</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.059162</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.479057</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.473298</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 23 columns</p>\n</div>\n```\n:::\n:::\n\n\nThe result of `transform_1` is that the features that have been generated by \nthe `OneHotEncoder` are then scaled by the `StandardScaler`, because the new \nfeatures are numeric and are therefore selected in the next step. \n\nIn many cases, this behavior is not desired: while some model types may not be \naffected by the different ordering (such as tree-based models), linear models\nand NN-based models may produce worse results.\n\n## Conclusions\nIn this chapter we explored how skrub helps with selecting and transforming \nspecific columns using various transformers. While these transformers can take \nsimple lists of columns to work, they become far more flexible and powerful when\nthey are combined with the skrub selectors, which is the subject of the next \nchapter.\n\n",
    "supporting": [
      "03_feat_eng_apply_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js\" integrity=\"sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js\" integrity=\"sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}